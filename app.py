import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
import yfinance as yf
import requests
from scipy import stats
import json
import os
import sqlite3
from io import BytesIO
import base64
from datetime import datetime, timezone
from pathlib import Path

try:
    from google.oauth2.credentials import Credentials
    from google.oauth2.service_account import Credentials as ServiceAccountCredentials
    from google.auth.transport.requests import Request
    from googleapiclient.discovery import build
    from googleapiclient.errors import HttpError
    from googleapiclient.http import MediaIoBaseUpload
    from google_auth_oauthlib.flow import InstalledAppFlow
except ModuleNotFoundError:
    Credentials = None
    ServiceAccountCredentials = None
    Request = None
    build = None
    HttpError = Exception
    MediaIoBaseUpload = None
    InstalledAppFlow = None

try:
    import openai
except ModuleNotFoundError:
    openai = None  # Streamlit UI still loads; AI report generation will prompt to install

# --- Page Config ---
st.set_page_config(page_title="Portfolio Dashboard", layout="wide")
st.title("Team Portfolio Analysis Dashboard")

# ==============================================================================
# [Helper Functions] - Fixed Timezone Issues
# ==============================================================================
def _clean_symbol(symbol):
    if symbol is None:
        return None
    if isinstance(symbol, (int, np.integer)):
        return str(symbol)
    if isinstance(symbol, float) and symbol.is_integer():
        return str(int(symbol))
    s = str(symbol).strip()
    if s.lower() in ("nan", "none", ""):
        return None
    if s.endswith(".0") and s.replace(".", "", 1).isdigit():
        return s[:-2]
    return s

def normalize_yf_ticker(symbol, currency=None):
    sym = _clean_symbol(symbol)
    if not sym:
        return None
    if "." in sym:
        return sym
    curr = str(currency).strip().upper() if currency is not None else ""
    if sym.isdigit():
        if curr == "HKD":
            return f"{sym.zfill(4)}.HK"
        if curr == "JPY":
            return f"{sym.zfill(4)}.T"
    if curr == "HKD":
        return f"{sym}.HK"
    if curr == "JPY":
        return f"{sym}.T"
    return sym

def is_etf_value(value):
    if value is None:
        return False
    return "ETF" in str(value).strip().upper()

@st.cache_data(ttl=3600)
def fetch_sectors_cached(tickers):
    sector_map = {}
    for t in tickers:
        try:
            t_str = str(t).strip()
            if t_str:
                info = yf.Ticker(t_str).info
                sector_map[t] = info.get('sector', 'Unknown')
            else:
                sector_map[t] = 'Unknown'
        except:
            sector_map[t] = 'Unknown'
    return sector_map

def _normalize_sp500_symbol(symbol):
    sym = _clean_symbol(symbol)
    if not sym:
        return None
    return sym.replace(".", "-")

@st.cache_data(ttl=3600)
def fetch_sp500_weights():
    url = "https://www.slickcharts.com/sp500"
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        resp = requests.get(url, headers=headers, timeout=20)
        resp.raise_for_status()
    except Exception:
        return pd.DataFrame()

    try:
        from bs4 import BeautifulSoup
    except ModuleNotFoundError:
        return pd.DataFrame()

    soup = BeautifulSoup(resp.text, "html.parser")
    tables = soup.find_all("table")
    for table in tables:
        headers = [th.get_text(strip=True) for th in table.find_all("th")]
        if "Symbol" in headers and "Weight" in headers:
            symbol_idx = headers.index("Symbol")
            weight_idx = headers.index("Weight")
            rows = []
            for tr in table.find_all("tr")[1:]:
                cols = [td.get_text(strip=True) for td in tr.find_all("td")]
                if len(cols) <= max(symbol_idx, weight_idx):
                    continue
                symbol = cols[symbol_idx]
                weight_str = cols[weight_idx].replace("%", "").replace(",", "")
                try:
                    weight = float(weight_str) / 100.0
                except ValueError:
                    continue
                rows.append({"Symbol": symbol, "Weight": weight})
            return pd.DataFrame(rows)
    return pd.DataFrame()

@st.cache_data(ttl=3600)
def fetch_sp500_sector_map():
    url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        resp = requests.get(url, headers=headers, timeout=20)
        resp.raise_for_status()
    except Exception:
        return pd.DataFrame()

    try:
        from bs4 import BeautifulSoup
    except ModuleNotFoundError:
        return pd.DataFrame()

    def _norm(text):
        return "".join(str(text).split()).lower()

    soup = BeautifulSoup(resp.text, "html.parser")
    for table in soup.find_all("table"):
        headers = [th.get_text(strip=True) for th in table.find_all("th")]
        if not headers:
            continue
        norm_headers = [_norm(h) for h in headers]
        if "symbol" in norm_headers and "gicssector" in norm_headers:
            sym_idx = norm_headers.index("symbol")
            sec_idx = norm_headers.index("gicssector")
            rows = []
            for tr in table.find_all("tr")[1:]:
                cols = [td.get_text(strip=True) for td in tr.find_all("td")]
                if len(cols) <= max(sym_idx, sec_idx):
                    continue
                rows.append({"Symbol": cols[sym_idx], "Sector": cols[sec_idx]})
            return pd.DataFrame(rows)
    return pd.DataFrame()

@st.cache_data(ttl=3600)
def fetch_sp500_sector_weights():
    weights = fetch_sp500_weights()
    if weights.empty:
        return pd.Series(dtype=float)
    sector_map = fetch_sp500_sector_map()
    if sector_map.empty:
        return pd.Series(dtype=float)
    merged = weights.merge(sector_map, on="Symbol", how="left")
    merged["Sector"] = merged["Sector"].fillna("Unknown")
    return merged.groupby("Sector")["Weight"].sum().sort_values(ascending=False)

@st.cache_data
def load_portfolio_snapshot(file_path, mtime):
    try:
        df_raw = pd.read_excel(file_path, sheet_name=0, header=None, engine="openpyxl")
        h_idx = -1
        for i in range(min(20, len(df_raw))):
            row_vals = [str(x).strip() for x in df_raw.iloc[i].values]
            if "ê¸°ì¤€ì¼ì" in row_vals and ("ì¢…ëª©ëª…" in row_vals or "ì¢…ëª©ì½”ë“œ" in row_vals or "ì‹¬ë³¼" in row_vals):
                h_idx = i
                break
        if h_idx == -1:
            return None, "Header not found"
        raw_cols = [str(c).strip() for c in df_raw.iloc[h_idx].tolist()]
        valid_indices = [i for i, c in enumerate(raw_cols) if c not in ["nan", "None", ""]]
        new_cols = []
        seen = {}
        for i in valid_indices:
            c_str = raw_cols[i]
            if c_str in seen:
                seen[c_str] += 1
                new_cols.append(f"{c_str}_{seen[c_str]}")
            else:
                seen[c_str] = 0
                new_cols.append(c_str)

        df = df_raw.iloc[h_idx + 1 :, valid_indices].copy()
        df.columns = new_cols
        if "ê¸°ì¤€ì¼ì" in df.columns:
            df["ê¸°ì¤€ì¼ì"] = pd.to_datetime(df["ê¸°ì¤€ì¼ì"], errors="coerce")
            df = df.dropna(subset=["ê¸°ì¤€ì¼ì"])

        cols_num = [
            "ì›í™”í‰ê°€ê¸ˆì•¡",
            "ì›í™”ì´í‰ê°€ì†ìµ",
            "ì›í™”ì´ë§¤ë§¤ì†ìµ",
            "í™˜ì†ìµ",
            "ì”ê³ ìˆ˜ëŸ‰",
            "ì™¸í™”í‰ê°€ê¸ˆì•¡",
            "í‰ê°€í™˜ìœ¨",
        ]
        for c in cols_num:
            if c in df.columns:
                df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0)

        return df, None
    except Exception as e:
        return None, str(e)

@st.cache_data
def download_benchmarks_all(start_date, end_date):
    """Download benchmarks for US, KR, HK, JP"""
    tickers = {'US': '^GSPC', 'KR': '^KS11', 'HK': '^HSI', 'JP': '^N225'}
    try:
        data = yf.download(list(tickers.values()), start=start_date, end=end_date + pd.Timedelta(days=5), progress=False)
        if 'Adj Close' in data.columns: df = data['Adj Close']
        elif 'Close' in data.columns: df = data['Close']
        else: df = data
        
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
        
        # [FIX] Remove Timezone
        if isinstance(df.index, pd.DatetimeIndex) and df.index.tz is not None:
            df.index = df.index.tz_localize(None)
            
        inv_map = {v: k for k, v in tickers.items()}
        df.rename(columns=inv_map, inplace=True)
        return df.ffill().pct_change().fillna(0)
    except:
        return pd.DataFrame()

@st.cache_data
def download_usdkrw(start_date, end_date):
    """Download USD/KRW Exchange Rate"""
    try:
        fx = yf.download('KRW=X', start=start_date, end=end_date + pd.Timedelta(days=5), progress=False)
        if 'Adj Close' in fx.columns: fx = fx['Adj Close']
        elif 'Close' in fx.columns: fx = fx['Close']
        
        if isinstance(fx.columns, pd.MultiIndex): fx.columns = fx.columns.get_level_values(0)
        
        # [FIX] Remove Timezone
        if isinstance(fx.index, pd.DatetimeIndex) and fx.index.tz is not None:
            fx.index = fx.index.tz_localize(None)
        
        if isinstance(fx, pd.Series): 
            fx = fx.to_frame(name='USD_KRW')
        else: 
            fx.rename(columns={'KRW=X': 'USD_KRW'}, inplace=True)
            if 'USD_KRW' not in fx.columns and not fx.empty:
                 fx.columns = ['USD_KRW']
        
        return fx.ffill()
    except:
        return pd.DataFrame()

@st.cache_data
def download_cross_assets(start_date, end_date):
    assets = {
        'S&P 500': '^GSPC', 'Nasdaq': '^IXIC', 'KOSPI': '^KS11', 
        'USD/KRW': 'KRW=X', 'US 10Y Yield': '^TNX', 'Gold': 'GC=F', 'Crude Oil': 'CL=F'
    }
    try:
        data = yf.download(list(assets.values()), start=start_date, end=end_date + pd.Timedelta(days=5), progress=False)
        if 'Adj Close' in data.columns: df = data['Adj Close']
        elif 'Close' in data.columns: df = data['Close']
        else: df = data
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
        
        # [FIX] Remove Timezone
        if isinstance(df.index, pd.DatetimeIndex) and df.index.tz is not None:
            df.index = df.index.tz_localize(None)

        df.rename(columns={v: k for k, v in assets.items()}, inplace=True)
        return df # Returns Prices
    except:
        return pd.DataFrame()

FACTOR_TARGET_COUNT = 15

@st.cache_data
def download_factors(start_date, end_date, return_prices=False):
    """Download diverse factor proxies (ETFs)"""
    factors = {
        'Global Mkt': 'ACWI', 'Value': 'VLUE', 'Growth': 'IWF', 'Momentum': 'MTUM',
        'Quality': 'QUAL', 'Low Vol': 'USMV', 'Small Cap': 'IWM', 'Emerging': 'EEM', 
        'Bond': 'TLT', 'USD': 'UUP', 'Gold': 'GLD', 'Oil': 'USO',
        'High Beta': 'SPHB', 'Meme': 'MEME', 'Spec Tech': 'ARKK'
    }
    try:
        if pd.isna(start_date) or pd.isna(end_date):
            return pd.DataFrame()
        data = yf.download(list(factors.values()), start=start_date, end=end_date + pd.Timedelta(days=5), progress=False)
        if 'Adj Close' in data.columns: df = data['Adj Close']
        elif 'Close' in data.columns: df = data['Close']
        else: df = data
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
        
        # [FIX] Remove Timezone
        if isinstance(df.index, pd.DatetimeIndex) and df.index.tz is not None:
            df.index = df.index.tz_localize(None)

        inv_map = {v: k for k, v in factors.items()}
        df.rename(columns=inv_map, inplace=True)
        df = df.ffill()
        if return_prices:
            return df
        return df.pct_change().fillna(0)
    except:
        return pd.DataFrame()

@st.cache_data
def download_global_indices(start_date, end_date):
    """Download global index prices for report context"""
    indices = {'SPX': '^GSPC', 'Hang Seng': '^HSI', 'Nikkei 225': '^N225', 'ACWI': 'ACWI'}
    try:
        data = yf.download(list(indices.values()), start=start_date, end=end_date + pd.Timedelta(days=5), progress=False)
        if 'Adj Close' in data.columns: df = data['Adj Close']
        elif 'Close' in data.columns: df = data['Close']
        else: df = data

        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
        
        # Align timezone handling with rest of app
        if isinstance(df.index, pd.DatetimeIndex) and df.index.tz is not None:
            df.index = df.index.tz_localize(None)
        
        df.rename(columns={v: k for k, v in indices.items()}, inplace=True)
        return df.ffill()
    except:
        return pd.DataFrame()

@st.cache_data
def download_price_history(tickers, start_date, end_date):
    tickers = [t for t in tickers if t]
    if not tickers or pd.isna(start_date) or pd.isna(end_date):
        return pd.DataFrame()
    try:
        data = yf.download(tickers, start=start_date, end=end_date + pd.Timedelta(days=5), progress=False)
        if 'Adj Close' in data.columns: df = data['Adj Close']
        elif 'Close' in data.columns: df = data['Close']
        else: df = data
        if isinstance(df, pd.Series):
            df = df.to_frame()
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
        if isinstance(df.index, pd.DatetimeIndex) and df.index.tz is not None:
            df.index = df.index.tz_localize(None)
        return df.ffill()
    except:
        return pd.DataFrame()

@st.cache_data(ttl=3600)
def fetch_latest_prices(tickers):
    """ì „ì¼ ì¢…ê°€ ê¸°ì¤€ìœ¼ë¡œ ê°€ê²© ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    prices = {}
    for t in tickers:
        if not t:
            continue
        try:
            ticker = yf.Ticker(t)
            hist = ticker.history(period="5d")
            if not hist.empty:
                prices[t] = hist['Close'].iloc[-1]
        except:
            pass
    return prices

def simulate_portfolio_nav(holdings_df, weight_adjustments, new_positions, base_nav, simulation_days=30, additional_cash=0, original_nav=None):
    """
    í¬íŠ¸í´ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜ ìˆ˜í–‰

    Args:
        holdings_df: í˜„ì¬ ë³´ìœ  ì¢…ëª© DataFrame (YF_Symbol, Weight, ì›í™”í‰ê°€ê¸ˆì•¡ í¬í•¨)
        weight_adjustments: dict {YF_Symbol: new_weight} - ê¸°ì¡´ ì¢…ëª© ë¹„ì¤‘ ì¡°ì ˆ
        new_positions: list of dict [{"ticker": str, "weight": float, "market": str}] - ì‹ ê·œ ì¢…ëª© ì¶”ê°€
        base_nav: ì‹œë®¬ë ˆì´ì…˜ ê¸°ì¤€ NAV (ì›í™”) - ì¶”ê°€ í˜„ê¸ˆ í¬í•¨ëœ ê¸ˆì•¡
        simulation_days: ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„ (ì¼)
        additional_cash: ì¶”ê°€ íˆ¬ì… í˜„ê¸ˆ (ì›í™”)
        original_nav: ì›ë˜ NAV (ì¶”ê°€ í˜„ê¸ˆ ë¯¸í¬í•¨)

    Returns:
        dict with simulation results
    """
    # original_navê°€ ì—†ìœ¼ë©´ base_nav ì‚¬ìš©
    if original_nav is None:
        original_nav = base_nav

    # 1. ëª¨ë“  í‹°ì»¤ ìˆ˜ì§‘ (ê¸°ì¡´ + ì‹ ê·œ)
    all_tickers = list(holdings_df["YF_Symbol"].dropna().unique())
    for pos in new_positions:
        if pos["ticker"] and pos["ticker"] not in all_tickers:
            all_tickers.append(pos["ticker"])

    if not all_tickers:
        return None

    # 2. ê³¼ê±° ê°€ê²© ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    end_date = pd.Timestamp.today().normalize()
    start_date = end_date - pd.Timedelta(days=simulation_days + 10)

    prices = download_price_history(all_tickers, start_date, end_date)
    if prices.empty:
        return None

    # ìµœê·¼ simulation_days ì¼ë§Œ ì‚¬ìš©
    prices = prices.tail(simulation_days + 1)

    # 3. ìˆ˜ìµë¥  ê³„ì‚°
    returns = prices.pct_change().fillna(0)

    # 4. ì›ë˜ ë¹„ì¤‘ìœ¼ë¡œ í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚°
    original_weights = holdings_df.set_index("YF_Symbol")["Weight"].to_dict()

    # 5. ì‹œë®¬ë ˆì´ì…˜ ë¹„ì¤‘ ê³„ì‚° (ì¶”ê°€ í˜„ê¸ˆ ë°˜ì˜)
    if additional_cash > 0:
        # ì¶”ê°€ í˜„ê¸ˆ íˆ¬ì… ì‹œ: ê¸°ì¡´ í¬ì§€ì…˜ ìœ ì§€ + ì¶”ê°€ ë§¤ìˆ˜
        # ê¸°ì¡´ ì¢…ëª©ì˜ ì‹¤ì œ ê¸ˆì•¡ ìœ ì§€, ìƒˆë¡œìš´ NAV ê¸°ì¤€ìœ¼ë¡œ ë¹„ì¤‘ ì¬ê³„ì‚°
        sim_weights = {}

        # ê¸°ì¡´ ì¢…ëª©: ê¸°ì¡´ ê¸ˆì•¡ / ìƒˆ NAV = ìƒˆ ë¹„ì¤‘
        for ticker, orig_weight in original_weights.items():
            original_value = orig_weight * original_nav  # ê¸°ì¡´ ê¸ˆì•¡
            sim_weights[ticker] = original_value / base_nav  # ìƒˆ NAV ê¸°ì¤€ ë¹„ì¤‘

        # ë¹„ì¤‘ ì¡°ì ˆì´ ìˆëŠ” ê²½ìš° (ì¦ê°€ë¶„ë§Œ ì¶”ê°€ í˜„ê¸ˆìœ¼ë¡œ ë§¤ìˆ˜)
        for ticker, new_weight in weight_adjustments.items():
            if ticker in sim_weights:
                old_weight_in_new_nav = sim_weights[ticker]
                # ëª©í‘œ ë¹„ì¤‘ì´ í˜„ì¬ ë¹„ì¤‘ë³´ë‹¤ ë†’ìœ¼ë©´ ì¶”ê°€ ë§¤ìˆ˜
                if new_weight > old_weight_in_new_nav:
                    sim_weights[ticker] = new_weight
                else:
                    # ë¹„ì¤‘ ì¶•ì†ŒëŠ” ë§¤ë„
                    sim_weights[ticker] = new_weight

        # ì‹ ê·œ ì¢…ëª© ì¶”ê°€ (ì¶”ê°€ í˜„ê¸ˆìœ¼ë¡œ ë§¤ìˆ˜)
        for pos in new_positions:
            if pos["ticker"] and pos["weight"] > 0:
                sim_weights[pos["ticker"]] = pos["weight"]
    else:
        # ì¶”ê°€ í˜„ê¸ˆ ì—†ìŒ: ê¸°ì¡´ ë¡œì§
        sim_weights = original_weights.copy()

        # ê¸°ì¡´ ì¢…ëª© ë¹„ì¤‘ ì¡°ì ˆ ì ìš©
        for ticker, new_weight in weight_adjustments.items():
            if ticker in sim_weights:
                sim_weights[ticker] = new_weight

        # ì‹ ê·œ ì¢…ëª© ì¶”ê°€
        for pos in new_positions:
            if pos["ticker"] and pos["weight"] > 0:
                sim_weights[pos["ticker"]] = pos["weight"]

    # ë¹„ì¤‘ ì •ê·œí™” (í•©ì´ 1ì´ ë˜ë„ë¡)
    total_weight = sum(sim_weights.values())
    if total_weight > 0:
        sim_weights = {k: v / total_weight for k, v in sim_weights.items()}

    # 6. ì›ë˜ í¬íŠ¸í´ë¦¬ì˜¤ NAV ê³„ì‚° (ì›ë˜ NAV ê¸°ì¤€)
    original_port_returns = pd.Series(0.0, index=returns.index)
    for ticker, weight in original_weights.items():
        if ticker in returns.columns:
            original_port_returns += returns[ticker] * weight

    orig_nav_series = original_nav * (1 + original_port_returns).cumprod()

    # 7. ì‹œë®¬ë ˆì´ì…˜ í¬íŠ¸í´ë¦¬ì˜¤ NAV ê³„ì‚° (ìƒˆ NAV ê¸°ì¤€)
    sim_port_returns = pd.Series(0.0, index=returns.index)
    for ticker, weight in sim_weights.items():
        if ticker in returns.columns:
            sim_port_returns += returns[ticker] * weight

    sim_nav_series = base_nav * (1 + sim_port_returns).cumprod()

    # 8. ì„¹í„° ì •ë³´ ìˆ˜ì§‘
    original_sectors = holdings_df.set_index("YF_Symbol")["ì„¹í„°"].to_dict() if "ì„¹í„°" in holdings_df.columns else {}

    # ì‹ ê·œ ì¢…ëª© ì„¹í„° ì¡°íšŒ
    new_tickers_for_sector = [pos["ticker"] for pos in new_positions if pos["ticker"] and pos["ticker"] not in original_sectors]
    if new_tickers_for_sector:
        new_sector_map = fetch_sectors_cached(tuple(new_tickers_for_sector))
        original_sectors.update(new_sector_map)

    return {
        "original_nav": orig_nav_series,
        "sim_nav": sim_nav_series,
        "original_weights": original_weights,
        "sim_weights": sim_weights,
        "returns": returns,
        "prices": prices,
        "sector_map": original_sectors,
        "additional_cash": additional_cash,
        "base_nav": base_nav,
        "original_nav_value": original_nav,
    }

def calculate_factor_exposure(weights, returns, simulation_days=30):
    """
    íŒ©í„° ìµìŠ¤í¬ì € ê³„ì‚° (ë² íƒ€ ê¸°ë°˜)

    Args:
        weights: dict {ticker: weight}
        returns: DataFrame of returns
        simulation_days: ë¶„ì„ ê¸°ê°„

    Returns:
        dict of factor exposures
    """
    # íŒ©í„° ETF ì •ì˜
    factor_etfs = {
        "Market (SPY)": "SPY",
        "Value (IWD)": "IWD",
        "Growth (IWF)": "IWF",
        "Momentum (MTUM)": "MTUM",
        "Quality (QUAL)": "QUAL",
        "Low Vol (USMV)": "USMV",
        "Small Cap (IWM)": "IWM",
        "EM (EEM)": "EEM",
    }

    # íŒ©í„° ê°€ê²© ë‹¤ìš´ë¡œë“œ
    end_date = pd.Timestamp.today().normalize()
    start_date = end_date - pd.Timedelta(days=simulation_days + 10)

    factor_prices = download_price_history(list(factor_etfs.values()), start_date, end_date)
    if factor_prices.empty:
        return {}

    factor_returns = factor_prices.pct_change().fillna(0).tail(simulation_days)

    # í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚°
    port_returns = pd.Series(0.0, index=returns.index)
    for ticker, weight in weights.items():
        if ticker in returns.columns:
            port_returns += returns[ticker] * weight

    port_returns = port_returns.tail(simulation_days)

    # ê° íŒ©í„°ì— ëŒ€í•œ ë² íƒ€ ê³„ì‚°
    exposures = {}
    for factor_name, factor_ticker in factor_etfs.items():
        if factor_ticker not in factor_returns.columns:
            continue
        factor_ret = factor_returns[factor_ticker]

        # ê³µí†µ ì¸ë±ìŠ¤
        common_idx = port_returns.index.intersection(factor_ret.index)
        if len(common_idx) < 10:
            continue

        p_ret = port_returns.loc[common_idx]
        f_ret = factor_ret.loc[common_idx]

        # ë² íƒ€ ê³„ì‚°
        cov = np.cov(p_ret, f_ret)[0, 1]
        var = np.var(f_ret)
        if var > 0:
            beta = cov / var
            exposures[factor_name] = beta

    return exposures

def calculate_portfolio_beta_multi_period(weights, lookback_periods=[30, 60, 90]):
    """
    ì—¬ëŸ¬ ê¸°ê°„ì— ëŒ€í•œ í¬íŠ¸í´ë¦¬ì˜¤ ë² íƒ€ ê³„ì‚° (êµ­ê°€ë³„ ë²¤ì¹˜ë§ˆí¬)

    Args:
        weights: dict {ticker: weight}
        lookback_periods: ë² íƒ€ ê³„ì‚° ê¸°ê°„ ë¦¬ìŠ¤íŠ¸ (ì¼)

    Returns:
        dict with beta values for each benchmark and period
    """
    if not weights:
        return {}

    # ë²¤ì¹˜ë§ˆí¬ ì •ì˜
    benchmarks = {
        "US (S&P 500)": "^GSPC",
        "KR (KOSPI)": "^KS11",
        "HK (HSI)": "^HSI",
        "JP (Nikkei)": "^N225",
    }

    tickers = [t for t in weights.keys() if t]
    if not tickers:
        return {}

    # ìµœëŒ€ ê¸°ê°„ + ì—¬ìœ ë¶„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    max_period = max(lookback_periods)
    end_date = pd.Timestamp.today().normalize()
    start_date = end_date - pd.Timedelta(days=max_period + 20)

    # í¬íŠ¸í´ë¦¬ì˜¤ ì¢…ëª© + ë²¤ì¹˜ë§ˆí¬ ê°€ê²© ë‹¤ìš´ë¡œë“œ
    all_tickers = tickers + list(benchmarks.values())
    prices = download_price_history(all_tickers, start_date, end_date)
    if prices.empty:
        return {}

    returns = prices.pct_change().dropna()

    # í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚°
    port_returns_full = pd.Series(0.0, index=returns.index)
    for ticker, weight in weights.items():
        if ticker in returns.columns:
            port_returns_full += returns[ticker] * weight

    # ê° ê¸°ê°„, ê° ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•´ ë² íƒ€ ê³„ì‚°
    results = {}
    for period in lookback_periods:
        period_key = f"{period}D"
        results[period_key] = {}

        port_returns = port_returns_full.tail(period)

        for bench_name, bench_ticker in benchmarks.items():
            if bench_ticker not in returns.columns:
                continue

            bench_returns = returns[bench_ticker].tail(period)

            # ê³µí†µ ì¸ë±ìŠ¤
            common_idx = port_returns.index.intersection(bench_returns.index)
            if len(common_idx) < 10:
                continue

            p_ret = port_returns.loc[common_idx]
            b_ret = bench_returns.loc[common_idx]

            # ë² íƒ€ ê³„ì‚°
            cov = np.cov(p_ret, b_ret)[0, 1]
            var = np.var(b_ret)
            if var > 0:
                beta = cov / var
                results[period_key][bench_name] = beta

    return results

def calculate_portfolio_factor_exposure(weights, lookback_days=60):
    """
    í¬íŠ¸í´ë¦¬ì˜¤ íŒ©í„° ìµìŠ¤í¬ì € ê³„ì‚°

    Args:
        weights: dict {ticker: weight}
        lookback_days: ë¶„ì„ ê¸°ê°„

    Returns:
        dict of factor exposures
    """
    if not weights:
        return {}

    # íŒ©í„° ETF ì •ì˜
    factor_etfs = {
        "Market": "SPY",
        "Value": "IWD",
        "Growth": "IWF",
        "Momentum": "MTUM",
        "Quality": "QUAL",
        "Low Vol": "USMV",
        "Small Cap": "IWM",
        "EM": "EEM",
    }

    tickers = [t for t in weights.keys() if t]
    if not tickers:
        return {}

    end_date = pd.Timestamp.today().normalize()
    start_date = end_date - pd.Timedelta(days=lookback_days + 20)

    # í¬íŠ¸í´ë¦¬ì˜¤ ì¢…ëª© + íŒ©í„° ETF ê°€ê²© ë‹¤ìš´ë¡œë“œ
    all_tickers = tickers + list(factor_etfs.values())
    prices = download_price_history(all_tickers, start_date, end_date)
    if prices.empty:
        return {}

    returns = prices.pct_change().dropna().tail(lookback_days)

    # í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚°
    port_returns = pd.Series(0.0, index=returns.index)
    for ticker, weight in weights.items():
        if ticker in returns.columns:
            port_returns += returns[ticker] * weight

    # ê° íŒ©í„°ì— ëŒ€í•œ ë² íƒ€ ê³„ì‚°
    exposures = {}
    for factor_name, factor_ticker in factor_etfs.items():
        if factor_ticker not in returns.columns:
            continue

        factor_ret = returns[factor_ticker]
        common_idx = port_returns.index.intersection(factor_ret.index)
        if len(common_idx) < 10:
            continue

        p_ret = port_returns.loc[common_idx]
        f_ret = factor_ret.loc[common_idx]

        cov = np.cov(p_ret, f_ret)[0, 1]
        var = np.var(f_ret)
        if var > 0:
            exposures[factor_name] = cov / var

    return exposures

@st.cache_data(ttl=3600)
def get_exchange_rates():
    """í™˜ìœ¨ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (USD ê¸°ì¤€)"""
    fx_tickers = {
        "KRW": "KRW=X",   # USD/KRW
        "JPY": "JPY=X",   # USD/JPY
        "HKD": "HKD=X",   # USD/HKD
    }
    rates = {"USD": 1.0}  # USDëŠ” ê¸°ë³¸ê°’ 1

    for currency, ticker in fx_tickers.items():
        try:
            data = yf.Ticker(ticker).history(period="5d")
            if not data.empty:
                rates[currency] = data['Close'].iloc[-1]
        except:
            # ê¸°ë³¸ê°’ ì„¤ì •
            if currency == "KRW":
                rates[currency] = 1400.0
            elif currency == "JPY":
                rates[currency] = 150.0
            elif currency == "HKD":
                rates[currency] = 7.8

    return rates

def calculate_trade_shares(original_weights, sim_weights, total_nav_krw, holdings_df, new_positions, original_nav=None, additional_cash=0):
    """
    ë§¤ë§¤í•´ì•¼ í•˜ëŠ” ì£¼ìˆ˜ ê³„ì‚°

    Args:
        original_weights: dict {ticker: weight} ì›ë˜ ë¹„ì¤‘
        sim_weights: dict {ticker: weight} ì‹œë®¬ë ˆì´ì…˜ ë¹„ì¤‘
        total_nav_krw: ì´ NAV (KRW) - ì‹œë®¬ë ˆì´ì…˜ ê¸°ì¤€ (ì¶”ê°€ í˜„ê¸ˆ í¬í•¨)
        holdings_df: ë³´ìœ  ì¢…ëª© DataFrame
        new_positions: ì‹ ê·œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸
        original_nav: ì›ë˜ NAV (ì¶”ê°€ í˜„ê¸ˆ ë¯¸í¬í•¨)
        additional_cash: ì¶”ê°€ íˆ¬ì… í˜„ê¸ˆ (KRW)

    Returns:
        list of dict with trade details
    """
    trades = []

    # original_navê°€ ì—†ìœ¼ë©´ total_nav_krw ì‚¬ìš©
    if original_nav is None:
        original_nav = total_nav_krw

    # í™˜ìœ¨ ê°€ì ¸ì˜¤ê¸°
    fx_rates = get_exchange_rates()

    # ëª¨ë“  í‹°ì»¤ ìˆ˜ì§‘
    all_tickers = list(set(original_weights.keys()) | set(sim_weights.keys()))

    # ê° í‹°ì»¤ì— ëŒ€í•´ ìµœì‹  ì¢…ê°€ ê°€ì ¸ì˜¤ê¸°
    ticker_prices = {}
    ticker_currencies = {}

    for ticker in all_tickers:
        try:
            data = yf.Ticker(ticker).history(period="5d")
            if not data.empty:
                ticker_prices[ticker] = data['Close'].iloc[-1]

            # í†µí™” ê²°ì •
            if ticker.endswith(".T"):
                ticker_currencies[ticker] = "JPY"
            elif ticker.endswith(".HK"):
                ticker_currencies[ticker] = "HKD"
            elif ticker.endswith(".KS") or ticker.endswith(".KQ"):
                ticker_currencies[ticker] = "KRW"
            else:
                ticker_currencies[ticker] = "USD"
        except:
            pass

    # holdings_dfì—ì„œ í†µí™” ì •ë³´ ì—…ë°ì´íŠ¸
    if "í†µí™”" in holdings_df.columns:
        for idx, row in holdings_df.iterrows():
            ticker = row.get("YF_Symbol")
            if ticker and ticker in ticker_currencies:
                currency = row.get("í†µí™”", "USD")
                if currency and str(currency).strip().upper() not in ["", "NAN", "N/A"]:
                    ticker_currencies[ticker] = str(currency).strip().upper()

    # ë§¤ë§¤ ê³„ì‚°
    for ticker in all_tickers:
        orig_w = original_weights.get(ticker, 0)
        sim_w = sim_weights.get(ticker, 0)
        weight_diff = sim_w - orig_w

        # í˜„ì§€ í†µí™” ê°€ê²©
        local_price = ticker_prices.get(ticker)
        if local_price is None:
            continue

        currency = ticker_currencies.get(ticker, "USD")

        # í™˜ìœ¨ (1 USD = X í˜„ì§€í†µí™”)
        fx_rate = fx_rates.get(currency, 1.0)

        # USD/KRW í™˜ìœ¨
        usd_krw = fx_rates.get("KRW", 1400.0)

        # ëª©í‘œ ê¸ˆì•¡ ë³€í™” ê³„ì‚° (ì¶”ê°€ í˜„ê¸ˆ ê³ ë ¤)
        if additional_cash > 0:
            # ì¶”ê°€ í˜„ê¸ˆ ëª¨ë“œ: ì›ë˜ ê¸ˆì•¡ê³¼ ëª©í‘œ ê¸ˆì•¡ì˜ ì°¨ì´ ê³„ì‚°
            original_value_krw = orig_w * original_nav  # ê¸°ì¡´ ë³´ìœ  ê¸ˆì•¡
            target_value_krw = sim_w * total_nav_krw    # ëª©í‘œ ê¸ˆì•¡ (ìƒˆ NAV ê¸°ì¤€)
            target_value_change_krw = target_value_krw - original_value_krw
        else:
            # ì¼ë°˜ ëª¨ë“œ: ë¹„ì¤‘ ì°¨ì´ë¡œ ê³„ì‚°
            target_value_change_krw = (sim_w - orig_w) * total_nav_krw

        if abs(target_value_change_krw) < 1000:  # 1000ì› ë¯¸ë§Œ ë³€í™”ëŠ” ë¬´ì‹œ
            continue

        # í˜„ì§€ í†µí™” ê¸ˆì•¡ ë³€í™”
        if currency == "KRW":
            target_value_change_local = target_value_change_krw
        else:
            # KRW -> USD -> í˜„ì§€í†µí™”
            target_value_change_usd = target_value_change_krw / usd_krw
            if currency == "USD":
                target_value_change_local = target_value_change_usd
            else:
                target_value_change_local = target_value_change_usd * fx_rate

        # ì£¼ìˆ˜ ê³„ì‚°
        shares = target_value_change_local / local_price if local_price > 0 else 0
        shares_rounded = int(round(shares))

        # ì¢…ëª©ëª… ì°¾ê¸°
        name_row = holdings_df[holdings_df["YF_Symbol"] == ticker]
        if len(name_row) > 0:
            name = name_row["ì¢…ëª©ëª…"].values[0]
        else:
            # ì‹ ê·œ ì¢…ëª©ì¸ ê²½ìš°
            name = ticker

        # ë§¤ë§¤ ë°©í–¥
        if shares_rounded > 0:
            action = "ë§¤ìˆ˜"
        elif shares_rounded < 0:
            action = "ë§¤ë„"
        else:
            continue

        trades.append({
            "í‹°ì»¤": ticker,
            "ì¢…ëª©ëª…": name,
            "ë§¤ë§¤": action,
            "ì£¼ìˆ˜": abs(shares_rounded),
            "í˜„ì§€í†µí™”ê°€ê²©": local_price,
            "í†µí™”": currency,
            "ì›ë˜ë¹„ì¤‘": orig_w,
            "ëª©í‘œë¹„ì¤‘": sim_w,
            "ë¹„ì¤‘ë³€í™”": weight_diff,
            "ë§¤ë§¤ê¸ˆì•¡(í˜„ì§€)": abs(shares_rounded * local_price),
            "ë§¤ë§¤ê¸ˆì•¡(KRW)": abs(target_value_change_krw),
        })

    return trades

def calculate_portfolio_volatility(weights, lookback_days=30):
    """
    í¬íŠ¸í´ë¦¬ì˜¤ ë³€ë™ì„± ê³„ì‚° (30ì¼ ê¸°ì¤€ í‘œì¤€í¸ì°¨)

    Args:
        weights: dict {ticker: weight}
        lookback_days: ë³€ë™ì„± ê³„ì‚° ê¸°ê°„ (ê¸°ë³¸ 30ì¼)

    Returns:
        dict with volatility metrics
    """
    if not weights:
        return None

    tickers = [t for t in weights.keys() if t]
    if not tickers:
        return None

    # ê°€ê²© ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    end_date = pd.Timestamp.today().normalize()
    start_date = end_date - pd.Timedelta(days=lookback_days + 10)

    prices = download_price_history(tickers, start_date, end_date)
    if prices.empty:
        return None

    # ìµœê·¼ lookback_days ì¼ë§Œ ì‚¬ìš©
    prices = prices.tail(lookback_days + 1)
    returns = prices.pct_change().dropna()

    if returns.empty or len(returns) < 5:
        return None

    # í¬íŠ¸í´ë¦¬ì˜¤ ì¼ì¼ ìˆ˜ìµë¥  ê³„ì‚°
    port_returns = pd.Series(0.0, index=returns.index)
    total_weight = 0
    for ticker, weight in weights.items():
        if ticker in returns.columns:
            port_returns += returns[ticker] * weight
            total_weight += weight

    if total_weight == 0:
        return None

    # ë³€ë™ì„± ê³„ì‚° (ì—°ìœ¨í™”)
    daily_vol = port_returns.std()
    annual_vol = daily_vol * np.sqrt(252)

    # ê°œë³„ ì¢…ëª© ë³€ë™ì„±
    individual_vols = {}
    for ticker in tickers:
        if ticker in returns.columns:
            ind_daily_vol = returns[ticker].std()
            individual_vols[ticker] = ind_daily_vol * np.sqrt(252)

    # ìµœëŒ€ ì†ì‹¤ (ê¸°ê°„ ë‚´)
    cumulative = (1 + port_returns).cumprod()
    rolling_max = cumulative.expanding().max()
    drawdown = (cumulative - rolling_max) / rolling_max
    max_drawdown = drawdown.min()

    # VaR (95%, 99%)
    var_95 = np.percentile(port_returns, 5)
    var_99 = np.percentile(port_returns, 1)

    return {
        "daily_volatility": daily_vol,
        "annual_volatility": annual_vol,
        "max_drawdown": max_drawdown,
        "var_95": var_95,
        "var_99": var_99,
        "individual_vols": individual_vols,
        "returns": port_returns,
    }

def align_factor_returns(port_index, factor_prices):
    if factor_prices is None or factor_prices.empty or port_index is None or len(port_index) == 0:
        return pd.DataFrame()
    aligned = factor_prices.reindex(port_index, method='ffill').ffill().bfill()
    return aligned.pct_change().fillna(0)

def calculate_holdings_beta(curr_hold, benchmark_map, end_date=None, lookback_days=252, min_obs=30):
    if curr_hold is None or curr_hold.empty:
        return {}
    if 'ì›í™”í‰ê°€ê¸ˆì•¡' not in curr_hold.columns:
        return {}

    hold = curr_hold.copy()
    if 'Symbol' in hold.columns and 'Ticker_ID' in hold.columns:
        base_symbol = hold['Symbol'].where(hold['Symbol'].notna(), hold['Ticker_ID'])
    elif 'Symbol' in hold.columns:
        base_symbol = hold['Symbol']
    else:
        base_symbol = hold['Ticker_ID']
    currencies = hold['í†µí™”'] if 'í†µí™”' in hold.columns else [None] * len(hold)
    hold['YF_Ticker'] = [
        normalize_yf_ticker(sym, cur) for sym, cur in zip(base_symbol, currencies)
    ]
    hold = hold.dropna(subset=['YF_Ticker'])
    hold['ì›í™”í‰ê°€ê¸ˆì•¡'] = pd.to_numeric(hold['ì›í™”í‰ê°€ê¸ˆì•¡'], errors='coerce').fillna(0)
    weights = hold.groupby('YF_Ticker')['ì›í™”í‰ê°€ê¸ˆì•¡'].sum()
    weights = weights[weights != 0]
    total = weights.sum()
    if total == 0:
        return {}
    weights = weights / total

    end_dt = end_date
    if end_dt is None or pd.isna(end_dt):
        end_dt = pd.Timestamp.today().normalize()
    end_dt = min(end_dt, pd.Timestamp.today().normalize())
    start_dt = end_dt - pd.Timedelta(days=int(lookback_days * 1.6))

    tickers = sorted(set(list(weights.index) + list(benchmark_map.values())))
    prices = download_price_history(tickers, start_dt, end_dt)
    if prices.empty:
        return {}
    returns = prices.pct_change()

    betas = {}
    for label, bench_ticker in benchmark_map.items():
        if bench_ticker not in returns.columns:
            continue
        bench_ret = returns[bench_ticker]
        weighted_sum = 0.0
        weight_total = 0.0
        for ticker, weight in weights.items():
            if ticker not in returns.columns:
                continue
            df = pd.concat([returns[ticker], bench_ret], axis=1).dropna()
            if len(df) < min_obs:
                continue
            cov = df.iloc[:, 0].cov(df.iloc[:, 1])
            var = df.iloc[:, 1].var()
            if pd.isna(var) or var == 0:
                continue
            beta = cov / var
            weighted_sum += weight * beta
            weight_total += weight
        if weight_total > 0:
            betas[label] = weighted_sum / weight_total
    return betas

def perform_factor_regression(port_ret, factor_ret):
    try:
        df = pd.concat([port_ret, factor_ret], axis=1).dropna()
        if len(df) < 3:
            return None, None, None
        factor_cols = list(df.columns[1:])
        max_factors = min(FACTOR_TARGET_COUNT, len(df) - 2)
        if len(factor_cols) > max_factors:
            keep = df[factor_cols].var().sort_values(ascending=False).index[:max_factors]
            df = pd.concat([df.iloc[:, [0]], df[keep]], axis=1)
            factor_cols = list(keep)
        Y, X = df.iloc[:, 0].values, df.iloc[:, 1:].values
        X_w_const = np.column_stack([np.ones(len(X)), X])
        betas, residuals, rank, s = np.linalg.lstsq(X_w_const, Y, rcond=None)
        
        names = ['Alpha'] + list(df.columns[1:])
        exposures = pd.Series(betas, index=names)
        contrib = pd.DataFrame(index=df.index)
        for i, f in enumerate(names[1:]): contrib[f] = df.iloc[:, 1+i] * betas[i+1]
        contrib['Alpha'] = betas[0]
        contrib['Unexplained'] = Y - (X_w_const @ betas)
        
        ss_tot = np.sum((Y - np.mean(Y))**2)
        ss_res = np.sum((Y - (X_w_const @ betas)) ** 2)
        r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else np.nan
        return exposures, contrib, r2
    except: return None, None, None

def calculate_alpha_beta(port_ret, bench_ret):
    try:
        df = pd.concat([port_ret, bench_ret], axis=1).dropna()
        df.columns = ['Port', 'Bench']
        if len(df) < 10: return np.nan, np.nan, np.nan
        slope, intercept, r_value, p_value, std_err = stats.linregress(df['Bench'], df['Port'])
        return intercept * 252, slope, r_value**2
    except: return np.nan, np.nan, np.nan

def calculate_rolling_beta(port_ret, bench_ret, window=60):
    try:
        df = pd.concat([port_ret, bench_ret], axis=1).dropna()
        if len(df) < window:
            return pd.Series(dtype=float)
        df.columns = ['Port', 'Bench']
        rolling_cov = df['Port'].rolling(window).cov(df['Bench'])
        rolling_var = df['Bench'].rolling(window).var()
        beta = rolling_cov / rolling_var
        return beta.dropna()
    except Exception:
        return pd.Series(dtype=float)

def create_manual_html_table(df, title=None):
    html = ''
    if title: html += f'<h5 style="margin-top:20px; margin-bottom:10px;">{title}</h5>'
    html += '<div style="overflow-x:auto;"><table style="width:100%; border-collapse: collapse; font-size: 0.9rem;">'
    html += '<thead style="background-color: #f8f9fa; border-bottom: 2px solid #dee2e6; color: black;"><tr>' 
    for col in df.columns:
        html += f'<th style="padding: 12px; text-align: center; white-space: nowrap;">{col}</th>'
    html += '</tr></thead><tbody>'
    for _, row in df.iterrows():
        html += '<tr style="border-bottom: 1px solid #dee2e6;">'
        for i, val in enumerate(row):
            align = 'left' if i == 0 else 'right'
            color = 'inherit'
            val_str = str(val)
            if '%' in val_str:
                if '-' in val_str: color = '#dc3545'
                else: color = '#198754'
            html += f'<td style="padding: 10px; text-align: {align}; color: {color}; white-space: nowrap;">{val}</td>'
        html += '</tr>'
    html += '</tbody></table></div>'
    return html


# ==============================================================================
# [AI Helper Functions: OpenAI & DeepSeek]
# ==============================================================================
def get_openai_api_key():
    """Resolve OpenAI API key, preferring the sidebar input (user-provided)."""
    if openai is None:
        return None
    api_key = st.sidebar.text_input(
        'ğŸ”‘ OpenAI API Key',
        type='password',
        help='Key is used only for report generation. Set OPENAI_API_KEY env/secret or enter here.',
        key='openai_api_key_input',
    )
    if api_key:
        openai.api_key = api_key
        return api_key

    if getattr(openai, 'api_key', None):
        return openai.api_key

    try:
        if hasattr(st, 'secrets') and 'OPENAI_API_KEY' in st.secrets:
            api_key = st.secrets['OPENAI_API_KEY']
    except Exception:
        api_key = None
    if not api_key:
        api_key = os.environ.get('OPENAI_API_KEY', '')
    if api_key:
        openai.api_key = api_key
    return api_key


def get_deepseek_api_key():
    """Resolve DeepSeek API key (sidebar input first)."""
    api_key = st.sidebar.text_input(
        'ğŸ§  DeepSeek API Key',
        type='password',
        help='Key is used only for report generation. Set DEEPSEEK_API_KEY env/secret or enter here.',
        key='deepseek_api_key_input',
    )
    if api_key:
        return api_key
    try:
        if hasattr(st, 'secrets') and 'DEEPSEEK_API_KEY' in st.secrets:
            api_key = st.secrets['DEEPSEEK_API_KEY']
    except Exception:
        api_key = None
    if not api_key:
        api_key = os.environ.get('DEEPSEEK_API_KEY', '')
    return api_key


def _build_openai_compatible_client(api_key, base_url=None):
    """Return a client compatible with both openai>=1.0 and <=0.28 styles."""
    if openai is None:
        return None
    try:
        from openai import OpenAI  # type: ignore
        return OpenAI(api_key=api_key, base_url=base_url) if base_url else OpenAI(api_key=api_key)
    except Exception:
        openai.api_key = api_key
        if base_url:
            openai.api_base = base_url
        return openai


def _translate_openai_error(err, provider="openai"):
    """Map OpenAI/DeepSeek errors to clearer, user-facing messages."""
    msg = str(err)
    lower = msg.lower()
    if "insufficient_balance" in lower or "insufficient balance" in lower or "error code: 402" in lower:
        return RuntimeError(f"{provider.capitalize()} balance/credit is exhausted. Please top up or use another API key.")
    if "insufficient_quota" in lower or "exceeded your current quota" in lower:
        return RuntimeError(f"{provider.capitalize()} quota exceeded. Please check plan/billing or try another API key.")
    if "invalid_api_key" in lower or "incorrect api key" in lower:
        return RuntimeError("Invalid API key. Please re-enter a valid key in the sidebar.")
    return err if isinstance(err, RuntimeError) else RuntimeError(msg)


def _calc_risk_metrics(ret_series):
    try:
        if ret_series is None:
            return {}
        if isinstance(ret_series, pd.Series):
            clean = ret_series.dropna()
        else:
            clean = pd.Series(ret_series).dropna()
        if clean.size < 2:
            return {}
        std = clean.std()
        if std == 0 or np.isnan(std):
            sharpe = np.nan
        else:
            sharpe = (clean.mean() / std) * np.sqrt(252)
        cum = (1 + clean).cumprod()
        peak = cum.cummax()
        drawdown = cum / peak - 1
        max_dd = drawdown.min()
        ann_vol = std * np.sqrt(252)
        return {
            'sharpe': float(sharpe),
            'max_drawdown': float(max_dd),
            'annual_vol': float(ann_vol),
        }
    except Exception:
        return {}


def _calc_perf_metrics(ret_series):
    try:
        if ret_series is None:
            return {}
        clean = ret_series.dropna() if isinstance(ret_series, pd.Series) else pd.Series(ret_series).dropna()
        if clean.size < 2:
            return {}
        total_return = (1 + clean).prod() - 1
        ann_factor = 252 / clean.size
        cagr = (1 + total_return) ** ann_factor - 1 if ann_factor > 0 else np.nan
        vol = clean.std() * np.sqrt(252)
        sharpe = (clean.mean() / clean.std()) * np.sqrt(252) if clean.std() > 0 else np.nan
        downside = clean[clean < 0]
        downside_std = downside.std()
        sortino = (clean.mean() / downside_std) * np.sqrt(252) if downside_std and downside_std > 0 else np.nan
        cum = (1 + clean).cumprod()
        peak = cum.cummax()
        max_dd = (cum / peak - 1).min()
        calmar = cagr / abs(max_dd) if max_dd and max_dd != 0 else np.nan
        win_rate = (clean > 0).sum() / (clean != 0).sum() if (clean != 0).sum() > 0 else np.nan
        return {
            'Total Return': float(total_return),
            'CAGR': float(cagr),
            'Annualized Volatility': float(vol),
            'Sharpe Ratio': float(sharpe),
            'Sortino Ratio': float(sortino),
            'Max Drawdown': float(max_dd),
            'Calmar Ratio': float(calmar),
            'Win Rate': float(win_rate),
        }
    except Exception:
        return {}


def _clean_metric_map(metric_map):
    if not isinstance(metric_map, dict):
        return {}
    cleaned = {}
    for k, v in metric_map.items():
        try:
            if v is None:
                cleaned[k] = None
            elif isinstance(v, (float, np.floating)) and not np.isfinite(v):
                cleaned[k] = None
            else:
                cleaned[k] = float(v)
        except Exception:
            cleaned[k] = None
    return cleaned


def _clean_risk_metrics(risk):
    if not isinstance(risk, dict):
        return {}
    portfolio = _clean_metric_map(risk.get('portfolio', {}))
    benchmarks_raw = risk.get('benchmarks', {})
    benchmarks = {}
    if isinstance(benchmarks_raw, dict):
        for name, metric_map in benchmarks_raw.items():
            if isinstance(metric_map, dict):
                benchmarks[name] = _clean_metric_map(metric_map)
    return {'portfolio': portfolio, 'benchmarks': benchmarks}


def _safe_float_or_none(value):
    try:
        if value is None:
            return None
        if isinstance(value, (float, np.floating)) and not np.isfinite(value):
            return None
        return float(value)
    except Exception:
        return None


def _serialize_stats_for_gpt(stats_res):
    out = {}
    for period, d in stats_res.items():
        if not d:
            continue
        try:
            top5 = d.get('top5')
            bot5 = d.get('bot5')
            ctry = d.get('ctry')
            sect = d.get('sect')
            factor = d.get('factor')
            idx = d.get('indices')
            risk = d.get('risk')
            hedge_contrib = d.get('hedge_contrib')
            hedge_pnl_krw = d.get('hedge_pnl_krw')
            out[period] = {
                'label': d.get('label'),
                'total_return': float(d.get('ret', 0.0)),
                'total_pnl_krw': float(d.get('pnl', 0.0)),
                'top5_contributors': top5.to_dict(orient='records') if hasattr(top5, 'to_dict') and not top5.empty else [],
                'bottom5_detractors': bot5.to_dict(orient='records') if hasattr(bot5, 'to_dict') and not bot5.empty else [],
                'country_contrib': ctry.to_dict() if hasattr(ctry, 'to_dict') else {},
                'sector_contrib': sect.to_dict() if hasattr(sect, 'to_dict') else {},
                'factor_contrib': factor.to_dict() if hasattr(factor, 'to_dict') else {},
                'indices_return': idx.to_dict() if hasattr(idx, 'to_dict') else {},
                'hedge_contrib': _safe_float_or_none(hedge_contrib),
                'hedge_pnl_krw': _safe_float_or_none(hedge_pnl_krw),
                'risk_metrics': _clean_risk_metrics(risk),
            }
        except Exception:
            continue
    return out


def generate_ai_weekly_report(stats_res, report_date, user_comment='', provider='openai', language='English'):
    """Generate weekly report via selected LLM provider."""
    if provider == 'deepseek':
        api_key = get_deepseek_api_key()
        base_url = 'https://api.deepseek.com'
        model = 'deepseek-chat'
    else:
        api_key = get_openai_api_key()
        base_url = None
        model = 'gpt-4o-mini'

    if not api_key:
        raise RuntimeError("API key is missing. Please enter it in the sidebar.")

    client = _build_openai_compatible_client(api_key, base_url=base_url)
    if client is None:
        raise RuntimeError("OpenAI-compatible client not available. Install the 'openai' package.")

    payload = _serialize_stats_for_gpt(stats_res)
    system_prompt = (
        "You are a professional global equity long-short hedge fund PM and quant alpha researcher. "
        "You write weekly performance reports that are analytical, data-driven, and concise. "
        "You NEVER invent numbers; you only interpret the structured data you are given. "
        "Assume the base currency is KRW. The audience is an internal investment committee."
    )
    comment_block = ""
    if user_comment:
        comment_block = (
            "\n\nAdditional PM comments (can be Korean or English, keep the intent but clean up the wording):\n"
            + user_comment
        )
    norm_lang = language.strip().lower()
    is_korean = norm_lang.startswith("ko") or "í•œêµ­" in norm_lang or "korean" in norm_lang or norm_lang == "kr"
    lang_hint = "Write the full report in Korean." if is_korean else "Write the full report in English."

    sections = [
        "1) Market & Macro Overview (very short, based only on factor/index performance you see in the data)",
        "2) Portfolio Performance Summary (WTD, MTD, QTD, YTD vs indices)",
        "3) Attribution (by country, sector, factor, hedge contribution, and key single names from top/bottom contributors)",
        "4) Risk & Volatility Review (beta/volatility impressions inferred from patterns in returns; call out realized volatility, drawdowns, Sharpe-style risk-adjusted performance, AND isolate/describe hedge PnL impact vs underlying equity)",
        "5) PM Action Items / Portfolio Changes (what to add, trim, hedge, or monitor, qualitatively)",
        "6) Quant / Signal Perspective (what seems to work: momentum, mean-reversion, factor tilts, etc.).",
    ]
    sections.append(
        "7) YTD Risk Metrics vs Benchmarks (report YTD Sharpe ratio, max drawdown, and annualized volatility for "
        "the portfolio and each benchmark, based on total hedged returns; compare and interpret; do not invent numbers "
        "if metrics are missing)."
    )
    sections.append(
        "8) Drawdown / Sharpe / Return Improvement Plan (build separate plans for YTD, QTD, and MTD performance; "
        "for each period, diagnose weaknesses and propose concrete actions; include country allocation adjustments "
        "and country-level volatility management; include an 'Expected Impact' summary with directional results; "
        "do not invent numbers if metrics are missing)."
    )
    deepseek_extra = (
        "\nUnder the YTD risk section, include a compact table with rows for Portfolio and each benchmark, "
        "and columns for Sharpe Ratio (YTD), Max Drawdown (YTD), and Annualized Volatility (YTD). "
        "Use the provided risk_metrics from the YTD block (computed on total hedged returns); if a metric is missing, "
        "write 'N/A' and do not guess. "
        "Then provide a short comparison vs benchmarks.\n"
        "For the improvement plan, create three subsections titled YTD, QTD, and MTD. "
        "In each subsection, include: (a) key weaknesses, (b) action items, "
        "(c) country allocation changes, and (d) country-level volatility control ideas. "
        "Also include a compact impact matrix per subsection with rows for Drawdown, Sharpe Ratio, and Return, "
        "and columns for Key Drivers, Proposed Actions, and Expected Direction. "
        "Base portfolio operation and improvement suggestions on the YTD risk comparison."
    )
    section_block = "\n".join(sections)

    user_prompt = (
        f"Today is the weekly review for the portfolio, with performance measured up to {report_date.date()}.\n"
        "Here is the structured performance & attribution data for WTD, MTD, QTD, and YTD in JSON format.\n"
        "Use ONLY this information to write a full weekly report. Do not fabricate any new figures.\n\n"
        f"Structured data:\n{json.dumps(payload, ensure_ascii=False, indent=2)}"
        f"{comment_block}\n\n"
        "Your report MUST be structured in the following sections:\n"
        f"{section_block}\n"
        f"{deepseek_extra}\n"
        "Write in a clear, bullet-point friendly style suitable for a weekly investment meeting note.\n"
        f"{lang_hint}"
    )

    try:
        resp = client.chat.completions.create(
            model=model,
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_prompt},
            ],
            temperature=0.3,
            max_tokens=1500,
        )
        return resp.choices[0].message.content.strip()
    except AttributeError:
        try:
            resp = client.ChatCompletion.create(
                model=model,
                messages=[
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': user_prompt},
                ],
                temperature=0.3,
                max_tokens=1500,
            )
            return resp["choices"][0]["message"]["content"].strip()
        except Exception as e_old:
            raise _translate_openai_error(e_old, provider)
    except Exception as e_new:
        raise _translate_openai_error(e_new, provider)


# ==============================================================================
# [PART 1] Team PNL Load
# ==============================================================================
@st.cache_data
def load_team_pnl_data(file):
    try:
        df_pnl_raw = pd.read_excel(file, sheet_name='PNL', header=None, engine='openpyxl')
        h_idx = -1
        for i in range(15):
            if 'ì¼ì' in [str(x).strip() for x in df_pnl_raw.iloc[i].values]:
                h_idx = i; break
        if h_idx == -1: return None, None, "PNL Header Not Found"
        
        raw_cols = df_pnl_raw.iloc[h_idx].tolist()
        new_cols = []
        seen = {}
        for c in raw_cols:
            c_str = str(c).strip()
            if c_str in ['nan', 'None', '']: continue
            if c_str in seen: seen[c_str] += 1; new_cols.append(f"{c_str}_{seen[c_str]}")
            else: seen[c_str] = 0; new_cols.append(c_str)
            
        df_pnl = df_pnl_raw.iloc[h_idx+1:].copy()
        valid_indices = [i for i, c in enumerate(df_pnl_raw.iloc[h_idx]) if str(c).strip() not in ['nan', 'None', '']]
        df_pnl = df_pnl.iloc[:, valid_indices]
        df_pnl.columns = new_cols
        date_col = [c for c in df_pnl.columns if 'ì¼ì' in c][0]
        df_pnl = df_pnl.set_index(date_col)
        df_pnl.index = pd.to_datetime(df_pnl.index, errors='coerce')
        df_pnl = df_pnl.dropna(how='all').apply(pd.to_numeric, errors='coerce').fillna(0)

        df_pos_raw = pd.read_excel(file, sheet_name='Position', header=None, engine='openpyxl')
        h_idx_pos = -1
        for i in range(15):
            if 'ì¼ì' in [str(x).strip() for x in df_pos_raw.iloc[i].values]:
                h_idx_pos = i; break
        
        raw_cols_pos = df_pos_raw.iloc[h_idx_pos].tolist()
        new_cols_pos = []
        seen_pos = {}
        for c in raw_cols_pos:
            c_str = str(c).strip()
            if c_str in ['nan', 'None', '']: continue
            if c_str in seen_pos: seen_pos[c_str] += 1; new_cols_pos.append(f"{c_str}_{seen_pos[c_str]}")
            else: seen_pos[c_str] = 0; new_cols_pos.append(c_str)
            
        df_pos = df_pos_raw.iloc[h_idx_pos+1:].copy()
        valid_indices_pos = [i for i, c in enumerate(df_pos_raw.iloc[h_idx_pos]) if str(c).strip() not in ['nan', 'None', '']]
        df_pos = df_pos.iloc[:, valid_indices_pos]
        df_pos.columns = new_cols_pos
        date_col_pos = [c for c in df_pos.columns if 'ì¼ì' in c][0]
        df_pos = df_pos.set_index(date_col_pos)
        df_pos.index = pd.to_datetime(df_pos.index, errors='coerce')
        df_pos = df_pos.dropna(how='all').apply(pd.to_numeric, errors='coerce').fillna(0)

        return df_pnl, df_pos, None
    except Exception as e: return None, None, f"Team PNL Error: {e}"

# ==============================================================================
# [PART 2] Cash Equity Load
# ==============================================================================
@st.cache_data
def load_cash_equity_data(file):
    debug_logs = []
    try:
        xls = pd.ExcelFile(file, engine='openpyxl')
        all_holdings = []
        df_hedge = pd.DataFrame()
        
        for sheet in xls.sheet_names:
            if 'hedge' in sheet.lower() or 'í—·ì§€' in sheet:
                try:
                    df_h = pd.read_excel(file, sheet_name=sheet, header=None, engine='openpyxl')
                    h_idx = -1
                    for i in range(15):
                        if 'ê¸°ì¤€ì¼ì' in [str(x).strip() for x in df_h.iloc[i].values]:
                            h_idx = i; break
                    if h_idx != -1:
                        raw_cols = [str(c).strip() for c in df_h.iloc[h_idx]]
                        new_cols = []
                        seen = {}
                        for c in raw_cols:
                            if c in seen: seen[c]+=1; new_cols.append(f"{c}_{seen[c]}")
                            else: seen[c]=0; new_cols.append(c)
                        df_h.columns = new_cols
                        df_h = df_h.iloc[h_idx+1:].copy()
                        df_h['ê¸°ì¤€ì¼ì'] = pd.to_datetime(df_h['ê¸°ì¤€ì¼ì'], errors='coerce')
                        df_h = df_h.dropna(subset=['ê¸°ì¤€ì¼ì']).set_index('ê¸°ì¤€ì¼ì').sort_index()
                        col_cum = next((c for c in df_h.columns if 'ëˆ„ì ' in c and 'ì´ì†ìµ' in c), None)
                        if col_cum:
                            df_h[col_cum] = pd.to_numeric(df_h[col_cum], errors='coerce').fillna(0)
                            daily_hedge = df_h[col_cum].diff().fillna(0)
                            if df_hedge.empty: df_hedge = daily_hedge.to_frame(name='Hedge_PnL_KRW')
                            else: df_hedge = df_hedge.add(daily_hedge.to_frame(name='Hedge_PnL_KRW'), fill_value=0)
                except: pass
            else:
                try:
                    df = pd.read_excel(file, sheet_name=sheet, header=None, engine='openpyxl')
                    h_idx = -1
                    for i in range(15):
                        row_vals = [str(x).strip() for x in df.iloc[i].values]
                        if 'ê¸°ì¤€ì¼ì' in row_vals and ('ì¢…ëª©ëª…' in row_vals or 'ì¢…ëª©ì½”ë“œ' in row_vals):
                            h_idx = i; break
                    if h_idx != -1:
                        raw_cols = [str(c).strip() for c in df.iloc[h_idx]]
                        new_cols = []
                        seen = {}
                        for c in raw_cols:
                            if c in seen: seen[c]+=1; new_cols.append(f"{c}_{seen[c]}")
                            else: seen[c]=0; new_cols.append(c)
                        df.columns = new_cols
                        df = df.iloc[h_idx+1:].copy()
                        if 'ê¸°ì¤€ì¼ì' in df.columns: all_holdings.append(df)
                except: pass

        if not all_holdings: return None, None, None, None, None, None, "Holdings ë°ì´í„° ì—†ìŒ"

        eq = pd.concat(all_holdings, ignore_index=True)
        eq['ê¸°ì¤€ì¼ì'] = pd.to_datetime(eq['ê¸°ì¤€ì¼ì'], errors='coerce')
        eq = eq.dropna(subset=['ê¸°ì¤€ì¼ì'])
        
        rename_map = {'í‰ê°€ë‹¨ê°€': 'Market_Price', 'ì™¸í™”í‰ê°€ê¸ˆì•¡': 'Market_Value', 'ì¢…ëª©ì½”ë“œ': 'Ticker', 'ì‹¬ë³¼': 'Symbol'}
        eq.rename(columns=rename_map, inplace=True)
        
        cols_num = ['ì›í™”í‰ê°€ê¸ˆì•¡', 'ì›í™”ì´í‰ê°€ì†ìµ', 'ì›í™”ì´ë§¤ë§¤ì†ìµ', 'í™˜ì†ìµ', 'ì”ê³ ìˆ˜ëŸ‰', 'Market_Price', 'Market_Value', 'ì™¸í™”í‰ê°€ì†ìµ', 'ì™¸í™”ì´ë§¤ë§¤ì†ìµ', 'í‰ê°€í™˜ìœ¨']
        for c in cols_num:
            if c in eq.columns: eq[c] = pd.to_numeric(eq[c], errors='coerce').fillna(0)

        id_col = 'Ticker' if 'Ticker' in eq.columns else 'Symbol'
        if id_col not in eq.columns: id_col = 'ì¢…ëª©ëª…'
        eq['Ticker_ID'] = eq[id_col].fillna('Unknown')

        if 'ì„¹í„°' not in eq.columns:
            if 'Symbol' in eq.columns:
                def _resolve_yf_symbol(row):
                    base = row.get('Symbol')
                    if base is None or (isinstance(base, str) and base.strip() == '') or pd.isna(base):
                        if 'Ticker_ID' in row:
                            base = row.get('Ticker_ID')
                    return normalize_yf_ticker(base, row.get('í†µí™”'))
                eq['YF_Symbol'] = eq.apply(_resolve_yf_symbol, axis=1)
                uniques = eq['YF_Symbol'].dropna().unique()
                sec_map = fetch_sectors_cached(tuple(uniques))
                eq['ì„¹í„°'] = eq['YF_Symbol'].map(sec_map).fillna('Unknown')
            else:
                eq['ì„¹í„°'] = 'Unknown'
        else:
            eq['ì„¹í„°'] = eq['ì„¹í„°'].fillna('Unknown')

        etf_mask = pd.Series(False, index=eq.index)
        if 'ìƒí’ˆêµ¬ë¶„' in eq.columns:
            etf_mask |= eq['ìƒí’ˆêµ¬ë¶„'].apply(is_etf_value)
        if 'ì¢…ëª©ëª…' in eq.columns:
            etf_mask |= eq['ì¢…ëª©ëª…'].apply(is_etf_value)
        eq.loc[etf_mask, 'ì„¹í„°'] = 'ETF'

        if 'í†µí™”' in eq.columns:
            curr_map = {'USD': 'US', 'HKD': 'HK', 'JPY': 'JP', 'KRW': 'KR', 'CNY': 'CN'}
            eq['Country'] = eq['í†µí™”'].map(curr_map).fillna('Other')
        else: eq['Country'] = 'Other'

        all_dates = sorted(eq['ê¸°ì¤€ì¼ì'].unique())
        all_tickers = eq['Ticker_ID'].unique()
        idx = pd.MultiIndex.from_product([all_dates, all_tickers], names=['ê¸°ì¤€ì¼ì', 'Ticker_ID'])
        grid = pd.DataFrame(index=idx).reset_index()
        
        eq_dedup = eq.drop_duplicates(subset=['ê¸°ì¤€ì¼ì', 'Ticker_ID'])
        daily_totals = None
        if {'ì›í™”ì´í‰ê°€ì†ìµ', 'ì›í™”ì´ë§¤ë§¤ì†ìµ'}.issubset(eq_dedup.columns):
            pnl_cols = ['ì›í™”ì´í‰ê°€ì†ìµ', 'ì›í™”ì´ë§¤ë§¤ì†ìµ']
            agg_cols = pnl_cols + (['í™˜ì†ìµ'] if 'í™˜ì†ìµ' in eq_dedup.columns else [])
            daily_totals = eq_dedup.groupby('ê¸°ì¤€ì¼ì')[agg_cols].sum().sort_index()
            daily_totals['Total_PnL_KRW_Cum'] = daily_totals['ì›í™”ì´í‰ê°€ì†ìµ'] + daily_totals['ì›í™”ì´ë§¤ë§¤ì†ìµ']
            if 'í™˜ì†ìµ' in daily_totals.columns:
                daily_totals['FX_PnL_KRW_Cum'] = daily_totals['í™˜ì†ìµ']
            else:
                daily_totals['FX_PnL_KRW_Cum'] = 0.0
            daily_totals['Local_PnL_KRW_Cum'] = daily_totals['Total_PnL_KRW_Cum'] - daily_totals['FX_PnL_KRW_Cum']
            daily_totals['Daily_PnL_KRW'] = daily_totals['Total_PnL_KRW_Cum'].diff().fillna(0)
            daily_totals['Daily_Local_PnL_KRW'] = daily_totals['Local_PnL_KRW_Cum'].diff().fillna(0)
        cols_keep = ['ì›í™”í‰ê°€ê¸ˆì•¡', 'ì›í™”ì´í‰ê°€ì†ìµ', 'ì›í™”ì´ë§¤ë§¤ì†ìµ', 'ì™¸í™”í‰ê°€ì†ìµ', 'ì™¸í™”ì´ë§¤ë§¤ì†ìµ', 'í†µí™”', 'ì„¹í„°', 'Country', 'ì¢…ëª©ëª…', 'Market_Value']
        cols_keep = [c for c in cols_keep if c in eq_dedup.columns]
        
        merged = pd.merge(grid, eq_dedup[['ê¸°ì¤€ì¼ì', 'Ticker_ID'] + cols_keep], on=['ê¸°ì¤€ì¼ì', 'Ticker_ID'], how='left')
        merged = merged.sort_values(['Ticker_ID', 'ê¸°ì¤€ì¼ì'])

        for c in ['ì›í™”ì´ë§¤ë§¤ì†ìµ', 'ì™¸í™”ì´ë§¤ë§¤ì†ìµ']:
            if c in merged.columns: merged[c] = merged.groupby('Ticker_ID')[c].ffill().fillna(0)
        for c in ['ì›í™”í‰ê°€ì†ìµ', 'ì™¸í™”í‰ê°€ì†ìµ', 'ì›í™”í‰ê°€ê¸ˆì•¡', 'Market_Value']:
            if c in merged.columns: merged[c] = merged[c].fillna(0)
        for c in ['í†µí™”', 'ì„¹í„°', 'Country', 'ì¢…ëª©ëª…']:
            if c in merged.columns: merged[c] = merged.groupby('Ticker_ID')[c].ffill().fillna('Unknown')

        merged['Cum_PnL_KRW'] = merged['ì›í™”ì´í‰ê°€ì†ìµ'] + merged['ì›í™”ì´ë§¤ë§¤ì†ìµ']
        merged['Daily_PnL_KRW'] = merged.groupby('Ticker_ID')['Cum_PnL_KRW'].diff().fillna(0)
        
        if 'Market_Value' in merged.columns:
            merged['Implied_FX'] = np.where((merged['ì›í™”í‰ê°€ê¸ˆì•¡']!=0) & (merged['Market_Value']!=0),
                                            merged['ì›í™”í‰ê°€ê¸ˆì•¡']/merged['Market_Value'], 0)
            if 'í†µí™”' in merged.columns:
                merged.loc[merged['í†µí™”']=='KRW', 'Implied_FX'] = 1.0
        else: merged['Implied_FX'] = 0
            
        fx_daily = merged[merged['Implied_FX']>0].groupby(['ê¸°ì¤€ì¼ì', 'í†µí™”'])['Implied_FX'].median().reset_index().rename(columns={'Implied_FX': 'Daily_FX'})
        merged = pd.merge(merged, fx_daily, on=['ê¸°ì¤€ì¼ì', 'í†µí™”'], how='left')
        merged['Daily_FX'] = merged.groupby('Ticker_ID')['Daily_FX'].ffill().fillna(1.0)
        merged['FX_Ret'] = merged.groupby('Ticker_ID')['Daily_FX'].pct_change().fillna(0)
        
        merged['Prev_MV_KRW'] = merged.groupby('Ticker_ID')['ì›í™”í‰ê°€ê¸ˆì•¡'].shift(1).fillna(0)
        
        daily_agg = merged.groupby('ê¸°ì¤€ì¼ì').agg({
            'ì›í™”í‰ê°€ê¸ˆì•¡': 'sum',
            'Prev_MV_KRW': 'sum'
        }).rename(columns={'ì›í™”í‰ê°€ê¸ˆì•¡': 'Total_MV_KRW', 'Prev_MV_KRW': 'Total_Prev_MV_KRW'})
        if daily_totals is not None:
            daily_agg = daily_agg.join(
                daily_totals[['Daily_PnL_KRW', 'Daily_Local_PnL_KRW', 'Total_PnL_KRW_Cum',
                              'Local_PnL_KRW_Cum', 'FX_PnL_KRW_Cum']],
                how='left'
            )
        else:
            daily_pnl = merged.groupby('ê¸°ì¤€ì¼ì')['Daily_PnL_KRW'].sum().rename('Daily_PnL_KRW')
            daily_agg = daily_agg.join(daily_pnl, how='left')
        
        merged = merged.merge(daily_agg['Total_Prev_MV_KRW'].rename('Day_Total_Prev'), on='ê¸°ì¤€ì¼ì', how='left')
        merged['Contrib_KRW'] = np.where(merged['Day_Total_Prev'] > 0, 
                                         merged['Daily_PnL_KRW'] / merged['Day_Total_Prev'], 0)
        
        contrib_sector = merged.groupby(['ê¸°ì¤€ì¼ì', 'ì„¹í„°'])['Contrib_KRW'].sum().reset_index()
        contrib_country = merged.groupby(['ê¸°ì¤€ì¼ì', 'Country'])['Contrib_KRW'].sum().reset_index()
        
        merged['Weight'] = np.where(merged['Day_Total_Prev']>0, merged['Prev_MV_KRW']/merged['Day_Total_Prev'], 0)
        daily_fx_ret = merged.groupby('ê¸°ì¤€ì¼ì').apply(lambda x: (x['FX_Ret'] * x['Weight']).sum()).rename('Port_FX_Ret')
        
        country_daily = merged.groupby(['ê¸°ì¤€ì¼ì', 'Country']).agg({
            'Daily_PnL_KRW': 'sum', 'Prev_MV_KRW': 'sum'
        }).reset_index()
        country_daily['Country_Ret'] = np.where(country_daily['Prev_MV_KRW']>0, 
                                                country_daily['Daily_PnL_KRW']/country_daily['Prev_MV_KRW'], 0)

        df_perf = daily_agg.join(df_hedge, how='outer').fillna(0)
        if 'Hedge_PnL_KRW' not in df_perf.columns:
            df_perf['Hedge_PnL_KRW'] = 0.0
        df_perf = df_perf.join(daily_fx_ret, how='left').fillna(0)
        
        min_d, max_d = df_perf.index.min(), df_perf.index.max()
        usdkrw = download_usdkrw(min_d, max_d)
        df_perf = df_perf.join(usdkrw, how='left').fillna(method='ffill').fillna(1400.0)
        if 'USD_KRW' not in df_perf.columns: df_perf['USD_KRW'] = 1400.0
        
        df_perf['Hedge_PnL_USD'] = df_perf['Hedge_PnL_KRW'] / df_perf['USD_KRW']
        df_perf['Total_Prev_MV_USD'] = df_perf['Total_Prev_MV_KRW'] / df_perf['USD_KRW']
        df_perf['Total_PnL_KRW'] = df_perf['Daily_PnL_KRW'] + df_perf['Hedge_PnL_KRW']
        
        denom_krw = df_perf['Total_Prev_MV_KRW'].replace(0, np.nan)
        denom_usd = df_perf['Total_Prev_MV_USD'].replace(0, np.nan)
        
        df_perf['Ret_Equity_KRW'] = df_perf['Daily_PnL_KRW'] / denom_krw
        df_perf['Ret_Total_KRW'] = df_perf['Total_PnL_KRW'] / denom_krw

        if 'Daily_Local_PnL_KRW' in df_perf.columns:
            df_perf['Daily_Local_PnL_USD'] = df_perf['Daily_Local_PnL_KRW'] / df_perf['USD_KRW']
            df_perf['Ret_Equity_Local'] = df_perf['Daily_Local_PnL_USD'] / denom_usd
        else:
            df_perf['Ret_Equity_Local'] = (1 + df_perf['Ret_Equity_KRW'].fillna(0)) / (1 + df_perf['Port_FX_Ret'].fillna(0)) - 1
        df_perf['Ret_Hedge_Local'] = df_perf['Hedge_PnL_USD'] / denom_usd
        df_perf['Ret_Total_Local'] = df_perf['Ret_Equity_Local'] + df_perf['Ret_Hedge_Local'].fillna(0)
        
        df_perf.fillna(0, inplace=True)
        if len(df_perf) > 1:
            df_perf = df_perf.iloc[1:]
        
        for c in ['Ret_Equity_KRW', 'Ret_Total_KRW', 'Ret_Equity_Local', 'Ret_Total_Local']:
            df_perf[c.replace('Ret', 'Cum')] = (1 + df_perf[c]).cumprod() - 1
            
        df_last = eq.sort_values('ê¸°ì¤€ì¼ì').groupby('Ticker_ID').tail(1)
        df_last['Final_PnL'] = df_last['ì›í™”ì´í‰ê°€ì†ìµ'] + df_last['ì›í™”ì´ë§¤ë§¤ì†ìµ']
        
        return df_perf, df_last, {'Sector':contrib_sector, 'Country':contrib_country}, country_daily, merged, debug_logs, None

    except Exception as e:
        return None, None, None, None, None, None, f"Process Error: {e}"


# ==============================================================================
# [MAIN UI]
# ==============================================================================
menu = st.sidebar.radio(
    "Dashboard Menu",
    ["ğŸ“Œ Portfolio Snapshot", "Total Portfolio (Team PNL)", "Cash Equity Analysis", "ğŸ“‘ Weekly Report Generator", "ğŸ“Š Swap Report Analysis"],
)

if menu == "ğŸ“Œ Portfolio Snapshot":
    st.subheader("ğŸ“Œ Portfolio Snapshot (2026_ë©€í‹°.xlsx)")
    script_dir = Path(__file__).resolve().parent
    candidates = []
    env_path = os.getenv("PORTFOLIO_XLSX_PATH")
    if env_path:
        candidates.append(Path(env_path))
    if hasattr(st, "secrets") and "PORTFOLIO_XLSX_PATH" in st.secrets:
        candidates.append(Path(st.secrets["PORTFOLIO_XLSX_PATH"]))
    candidates.extend([
        script_dir / "2026_ë©€í‹°.xlsx",
        Path.cwd() / "2026_ë©€í‹°.xlsx",
        Path.home() / "Desktop" / "Workspace" / "Team" / "2026_ë©€í‹°.xlsx",
    ])
    data_path = next((p for p in candidates if p.exists()), None)
    if data_path is None:
        st.error("2026_ë©€í‹°.xlsx íŒŒì¼ì´ ì•± í´ë”ì— ì—†ìŠµë‹ˆë‹¤.")
        st.caption("ì»¨í…Œì´ë„ˆ/ë°°í¬ í™˜ê²½ì—ì„œëŠ” ë¡œì»¬ íŒŒì¼ì´ ë³´ì´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        st.caption(
            "í•´ê²°: 1) íŒŒì¼ì„ ì•± í´ë”ì— ë³µì‚¬í•˜ê±°ë‚˜ 2) PORTFOLIO_XLSX_PATH í™˜ê²½ë³€ìˆ˜/ì‹œí¬ë¦¿ìœ¼ë¡œ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”."
        )
        st.caption("ê²€ìƒ‰ ê²½ë¡œ: " + " , ".join(str(p) for p in candidates))
    else:
        with st.spinner("í¬íŠ¸í´ë¦¬ì˜¤ í˜„í™© ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            df_snapshot, err = load_portfolio_snapshot(str(data_path), data_path.stat().st_mtime)
        if err or df_snapshot is None or df_snapshot.empty:
            st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {err}")
        else:
            latest_date = df_snapshot["ê¸°ì¤€ì¼ì"].max()
            latest_all = df_snapshot[df_snapshot["ê¸°ì¤€ì¼ì"] == latest_date].copy()

            if "ì›í™”í‰ê°€ê¸ˆì•¡" not in latest_all.columns and {"ì™¸í™”í‰ê°€ê¸ˆì•¡", "í‰ê°€í™˜ìœ¨"}.issubset(latest_all.columns):
                latest_all["ì›í™”í‰ê°€ê¸ˆì•¡"] = latest_all["ì™¸í™”í‰ê°€ê¸ˆì•¡"] * latest_all["í‰ê°€í™˜ìœ¨"]

            id_col = "ì‹¬ë³¼" if "ì‹¬ë³¼" in latest_all.columns else ("ì¢…ëª©ì½”ë“œ" if "ì¢…ëª©ì½”ë“œ" in latest_all.columns else "ì¢…ëª©ëª…")
            latest_all["Ticker_ID"] = latest_all[id_col].fillna(latest_all.get("ì¢…ëª©ëª…", latest_all[id_col]))
            if "ì¢…ëª©ëª…" not in latest_all.columns:
                latest_all["ì¢…ëª©ëª…"] = latest_all["Ticker_ID"]
            if "í†µí™”" not in latest_all.columns:
                latest_all["í†µí™”"] = "N/A"

            def _resolve_symbol(row):
                base = row.get(id_col)
                if base is None or (isinstance(base, str) and base.strip() == "") or pd.isna(base):
                    base = row.get("ì¢…ëª©ì½”ë“œ") if "ì¢…ëª©ì½”ë“œ" in latest_all.columns else row.get("Ticker_ID")
                return normalize_yf_ticker(base, row.get("í†µí™”"))
            latest_all["YF_Symbol"] = latest_all.apply(_resolve_symbol, axis=1)

            if "ì„¹í„°" not in latest_all.columns:
                tickers = tuple(sorted(latest_all["YF_Symbol"].dropna().unique()))
                sector_map = fetch_sectors_cached(tickers)
                latest_all["ì„¹í„°"] = latest_all["YF_Symbol"].map(sector_map).fillna("Unknown")
            else:
                latest_all["ì„¹í„°"] = latest_all["ì„¹í„°"].fillna("Unknown")

            etf_mask = pd.Series(False, index=latest_all.index)
            if "ìƒí’ˆêµ¬ë¶„" in latest_all.columns:
                etf_mask |= latest_all["ìƒí’ˆêµ¬ë¶„"].apply(is_etf_value)
            if "ì¢…ëª©ëª…" in latest_all.columns:
                etf_mask |= latest_all["ì¢…ëª©ëª…"].apply(is_etf_value)
            latest_all.loc[etf_mask, "ì„¹í„°"] = "ETF"
            latest_all["Is_ETF"] = etf_mask

            if "ì›í™”í‰ê°€ê¸ˆì•¡" not in latest_all.columns:
                st.error("ì›í™”í‰ê°€ê¸ˆì•¡ ì»¬ëŸ¼ì´ ì—†ì–´ ë¹„ì¤‘ ê³„ì‚°ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
                latest_all = pd.DataFrame()

            if latest_all.empty:
                st.warning("ìµœì‹ ì¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()

            latest_for_weights = latest_all[latest_all["ì›í™”í‰ê°€ê¸ˆì•¡"] != 0].copy()
            if latest_for_weights.empty:
                latest_for_weights = latest_all.copy()

            latest_for_weights["Group_ID"] = latest_for_weights["YF_Symbol"].fillna(latest_for_weights["Ticker_ID"])
            holdings = latest_for_weights.groupby("Group_ID", dropna=False).agg(
                ì›í™”í‰ê°€ê¸ˆì•¡=("ì›í™”í‰ê°€ê¸ˆì•¡", "sum"),
                ì¢…ëª©ëª…=("ì¢…ëª©ëª…", "first"),
                ì„¹í„°=("ì„¹í„°", "first"),
                í†µí™”=("í†µí™”", "first"),
                Ticker_ID=("Ticker_ID", "first"),
                Is_ETF=("Is_ETF", "first"),
            ).reset_index()
            total_mv = holdings["ì›í™”í‰ê°€ê¸ˆì•¡"].sum()
            holdings["Weight"] = np.where(total_mv > 0, holdings["ì›í™”í‰ê°€ê¸ˆì•¡"] / total_mv, 0)
            holdings["Label"] = holdings["ì¢…ëª©ëª…"].astype(str) + " (" + holdings["Group_ID"].astype(str) + ")"

            etf_weight = holdings.loc[holdings["ì„¹í„°"] == "ETF", "Weight"].sum() if not holdings.empty else 0
            holdings_non_etf = holdings[holdings["ì„¹í„°"] != "ETF"].copy()
            total_mv_non_etf = holdings_non_etf["ì›í™”í‰ê°€ê¸ˆì•¡"].sum()
            sector_weights = holdings_non_etf.groupby("ì„¹í„°")["ì›í™”í‰ê°€ê¸ˆì•¡"].sum().sort_values(ascending=False)
            sector_weights_pct = sector_weights / total_mv_non_etf if total_mv_non_etf else sector_weights * 0

            currency_weights = holdings.groupby("í†µí™”")["ì›í™”í‰ê°€ê¸ˆì•¡"].sum().sort_values(ascending=False)
            currency_weights_pct = currency_weights / total_mv if total_mv else currency_weights * 0

            total_pnl = latest_all.get("ì›í™”ì´í‰ê°€ì†ìµ", pd.Series(0, index=latest_all.index)).sum() + \
                        latest_all.get("ì›í™”ì´ë§¤ë§¤ì†ìµ", pd.Series(0, index=latest_all.index)).sum()
            fx_pnl = latest_all.get("í™˜ì†ìµ", pd.Series(0, index=latest_all.index)).sum()
            local_pnl = total_pnl - fx_pnl

            hhi = (holdings["Weight"] ** 2).sum() if not holdings.empty else 0
            eff_n = (1 / hhi) if hhi > 0 else 0
            top5_weight = holdings["Weight"].nlargest(5).sum() if not holdings.empty else 0

            # ì‹œë®¬ë ˆì´ì…˜ìš© holdings ë°ì´í„° ì¤€ë¹„
            holdings["YF_Symbol"] = holdings["Group_ID"]

            # íƒ­ ìƒì„±: í˜„í™© / ì‹œë®¬ë ˆì´ì…˜
            tab_snapshot, tab_simulation = st.tabs(["ğŸ“Š í¬íŠ¸í´ë¦¬ì˜¤ í˜„í™©", "ğŸ”¬ í¬íŠ¸í´ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜"])

            with tab_snapshot:
                c1, c2, c3, c4 = st.columns(4)
                c1.metric("ê¸°ì¤€ì¼ì", latest_date.strftime("%Y-%m-%d"))
                c2.metric("ì´ AUM (KRW)", f"{total_mv:,.0f}")
                c3.metric("Total PnL (KRW)", f"{total_pnl:,.0f}")
                c4.metric("Local PnL (KRW)", f"{local_pnl:,.0f}")

                c5, c6, c7, c8 = st.columns(4)
                c5.metric("ë³´ìœ  ì¢…ëª© ìˆ˜", f"{len(holdings):,}")
                c6.metric("Top 5 ë¹„ì¤‘", f"{top5_weight:.2%}")
                c7.metric("HHI", f"{hhi:.4f}")
                c8.metric("ìœ íš¨ ë³´ìœ  ì¢…ëª© ìˆ˜", f"{eff_n:.1f}")

                # í¬íŠ¸í´ë¦¬ì˜¤ ë³€ë™ì„± ê³„ì‚°
                current_weights = holdings.set_index("YF_Symbol")["Weight"].to_dict()
                with st.spinner("ë³€ë™ì„± ê³„ì‚° ì¤‘..."):
                    vol_metrics = calculate_portfolio_volatility(current_weights, lookback_days=30)

                if vol_metrics:
                    c9, c10, c11, c12 = st.columns(4)
                    c9.metric("30ì¼ ë³€ë™ì„± (ì—°ìœ¨)", f"{vol_metrics['annual_volatility']:.2%}")
                    c10.metric("30ì¼ MDD", f"{vol_metrics['max_drawdown']:.2%}")
                    c11.metric("VaR 95%", f"{vol_metrics['var_95']:.2%}")
                    c12.metric("VaR 99%", f"{vol_metrics['var_99']:.2%}")

                st.caption(f"ETF ë¹„ì¤‘: {etf_weight:.2%} (ì„¹í„° ë¹„ì¤‘/ë¹„êµëŠ” ETF ì œì™¸ ê¸°ì¤€)")

                st.markdown("#### ğŸ” ë³´ìœ  ì¢…ëª© ë¹„ì¤‘")
                top_holdings = holdings.sort_values("Weight", ascending=False).head(15)
                fig_hold = go.Figure(
                    data=go.Bar(
                        x=top_holdings["Label"],
                        y=top_holdings["Weight"],
                        text=[f"{w:.2%}" for w in top_holdings["Weight"]],
                        textposition="auto",
                    )
                )
                fig_hold.update_layout(yaxis_tickformat=".1%", xaxis_title="", yaxis_title="Weight")
                st.plotly_chart(fig_hold, use_container_width=True)

                st.markdown("#### ğŸ§­ ì„¹í„° ë¹„ì¤‘")
                fig_sector = go.Figure(
                    data=go.Pie(labels=sector_weights_pct.index, values=sector_weights_pct.values, hole=0.45)
                )
                fig_sector.update_traces(textinfo="percent+label")
                st.plotly_chart(fig_sector, use_container_width=True)

                st.markdown("#### ğŸ’± í†µí™” ë¹„ì¤‘")
                fig_fx = go.Figure(
                    data=go.Bar(
                        x=currency_weights_pct.index.astype(str),
                        y=currency_weights_pct.values,
                        text=[f"{w:.2%}" for w in currency_weights_pct.values],
                        textposition="auto",
                    )
                )
                fig_fx.update_layout(yaxis_tickformat=".1%", xaxis_title="", yaxis_title="Weight")
                st.plotly_chart(fig_fx, use_container_width=True)

                st.markdown("#### ğŸ†š S&P 500 ì„¹í„° Weight ì°¨ì´ (Portfolio - SP500)")
                with st.spinner("S&P 500 ì„¹í„° ê°€ì¤‘ì¹˜ ê³„ì‚° ì¤‘..."):
                    sp_sector = fetch_sp500_sector_weights()
                if sp_sector.empty:
                    st.warning("S&P 500 ì„¹í„° ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                else:
                    port_sector = sector_weights_pct.copy()
                    if "Unknown" in port_sector.index:
                        port_sector = port_sector.drop("Unknown")
                    sp_sector = sp_sector.drop("Unknown", errors="ignore")
                    if port_sector.sum() > 0:
                        port_sector = port_sector / port_sector.sum()
                    if sp_sector.sum() > 0:
                        sp_sector = sp_sector / sp_sector.sum()

                    all_sectors = sorted(set(port_sector.index) | set(sp_sector.index))
                    diff = port_sector.reindex(all_sectors, fill_value=0) - sp_sector.reindex(all_sectors, fill_value=0)
                    colors = np.where(diff.values >= 0, "#16a34a", "#dc2626")
                    fig_diff = go.Figure(
                        data=go.Bar(x=diff.index, y=diff.values, marker_color=colors)
                    )
                    fig_diff.update_layout(yaxis_tickformat=".1%", xaxis_title="", yaxis_title="Weight Difference")
                    st.plotly_chart(fig_diff, use_container_width=True)

                    comp = pd.DataFrame({
                        "Portfolio": port_sector.reindex(all_sectors, fill_value=0),
                        "S&P 500": sp_sector.reindex(all_sectors, fill_value=0),
                    })
                    comp["Diff"] = comp["Portfolio"] - comp["S&P 500"]
                    st.dataframe(comp.style.format("{:.2%}"))

                # í¬íŠ¸í´ë¦¬ì˜¤ ë² íƒ€ (30/60/90ì¼, êµ­ê°€ë³„)
                st.markdown("#### ğŸ“Š í¬íŠ¸í´ë¦¬ì˜¤ ë² íƒ€ (êµ­ê°€ë³„ ë²¤ì¹˜ë§ˆí¬)")
                st.caption("ê° êµ­ê°€ ë²¤ì¹˜ë§ˆí¬ ëŒ€ë¹„ í¬íŠ¸í´ë¦¬ì˜¤ ë² íƒ€ì…ë‹ˆë‹¤. ë² íƒ€ > 1ì´ë©´ ë²¤ì¹˜ë§ˆí¬ë³´ë‹¤ ë³€ë™ì„±ì´ í½ë‹ˆë‹¤.")

                with st.spinner("ë² íƒ€ ê³„ì‚° ì¤‘..."):
                    beta_results = calculate_portfolio_beta_multi_period(current_weights, [30, 60, 90])

                if beta_results:
                    # ë² íƒ€ ë°ì´í„° ì •ë¦¬
                    beta_data = []
                    for period, benchmarks in beta_results.items():
                        for bench_name, beta_val in benchmarks.items():
                            beta_data.append({
                                "ê¸°ê°„": period,
                                "ë²¤ì¹˜ë§ˆí¬": bench_name,
                                "ë² íƒ€": beta_val
                            })

                    if beta_data:
                        df_beta = pd.DataFrame(beta_data)

                        # ë² íƒ€ ì°¨íŠ¸ (ê·¸ë£¹ ë°” ì°¨íŠ¸)
                        fig_beta = go.Figure()

                        periods = ["30D", "60D", "90D"]
                        colors = {"30D": "#3b82f6", "60D": "#8b5cf6", "90D": "#ec4899"}

                        for period in periods:
                            period_data = df_beta[df_beta["ê¸°ê°„"] == period]
                            if not period_data.empty:
                                fig_beta.add_trace(go.Bar(
                                    name=period,
                                    x=period_data["ë²¤ì¹˜ë§ˆí¬"],
                                    y=period_data["ë² íƒ€"],
                                    text=[f"{v:.2f}" for v in period_data["ë² íƒ€"]],
                                    textposition="auto",
                                    marker_color=colors.get(period, "#6366f1")
                                ))

                        fig_beta.add_hline(y=1.0, line_dash="dash", line_color="red",
                                          annotation_text="Beta = 1", annotation_position="right")
                        fig_beta.update_layout(
                            barmode="group",
                            xaxis_title="",
                            yaxis_title="Beta",
                            legend_title="ê¸°ê°„",
                            legend=dict(yanchor="top", y=0.99, xanchor="right", x=0.99)
                        )
                        st.plotly_chart(fig_beta, use_container_width=True)

                        # ë² íƒ€ í…Œì´ë¸”
                        df_beta_pivot = df_beta.pivot(index="ë²¤ì¹˜ë§ˆí¬", columns="ê¸°ê°„", values="ë² íƒ€")
                        df_beta_pivot = df_beta_pivot.reindex(columns=["30D", "60D", "90D"])
                        st.dataframe(df_beta_pivot.style.format("{:.3f}").background_gradient(cmap="RdYlGn_r", vmin=0.5, vmax=1.5))
                else:
                    st.warning("ë² íƒ€ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                # íŒ©í„° ìµìŠ¤í¬ì €
                st.markdown("#### ğŸ“ˆ íŒ©í„° ìµìŠ¤í¬ì € (Factor Exposure)")
                st.caption("íŒ©í„° ETF ëŒ€ë¹„ ë² íƒ€ë¡œ ì¸¡ì •í•œ ìµìŠ¤í¬ì €ì…ë‹ˆë‹¤. (60ì¼ ê¸°ì¤€)")

                with st.spinner("íŒ©í„° ìµìŠ¤í¬ì € ê³„ì‚° ì¤‘..."):
                    factor_exposures = calculate_portfolio_factor_exposure(current_weights, lookback_days=60)

                if factor_exposures:
                    # íŒ©í„° ìµìŠ¤í¬ì € ì°¨íŠ¸
                    factors = list(factor_exposures.keys())
                    values = list(factor_exposures.values())

                    colors_factor = ["#16a34a" if v >= 0 else "#dc2626" for v in values]

                    fig_factor = go.Figure(data=go.Bar(
                        x=factors,
                        y=values,
                        text=[f"{v:.2f}" for v in values],
                        textposition="auto",
                        marker_color=colors_factor
                    ))
                    fig_factor.add_hline(y=1.0, line_dash="dash", line_color="gray",
                                        annotation_text="Exposure = 1", annotation_position="right")
                    fig_factor.update_layout(
                        xaxis_title="",
                        yaxis_title="Factor Beta",
                    )
                    st.plotly_chart(fig_factor, use_container_width=True)

                    # íŒ©í„° ìµìŠ¤í¬ì € í…Œì´ë¸”
                    df_factor = pd.DataFrame({
                        "íŒ©í„°": factors,
                        "ìµìŠ¤í¬ì €": values
                    })
                    df_factor = df_factor.sort_values("ìµìŠ¤í¬ì €", ascending=False)
                    st.dataframe(df_factor.style.format({"ìµìŠ¤í¬ì €": "{:.3f}"}).background_gradient(
                        subset=["ìµìŠ¤í¬ì €"], cmap="RdYlGn", vmin=-0.5, vmax=1.5
                    ))
                else:
                    st.warning("íŒ©í„° ìµìŠ¤í¬ì €ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                st.markdown("#### ğŸ“‹ ë³´ìœ  ì¢…ëª© ìƒì„¸")
                show_cols = ["Group_ID", "ì¢…ëª©ëª…", "ì„¹í„°", "í†µí™”", "ì›í™”í‰ê°€ê¸ˆì•¡", "Weight"]
                show_cols = [c for c in show_cols if c in holdings.columns]
                st.dataframe(holdings.sort_values("Weight", ascending=False)[show_cols].style.format({
                    "ì›í™”í‰ê°€ê¸ˆì•¡": "{:,.0f}",
                    "Weight": "{:.2%}",
                }))

            with tab_simulation:
                st.markdown("### ğŸ”¬ í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘ ì‹œë®¬ë ˆì´ì…˜")
                st.caption("ê¸°ì¡´ ì¢…ëª©ì˜ ë¹„ì¤‘ì„ ì¡°ì ˆí•˜ê±°ë‚˜ ì‹ ê·œ ì¢…ëª©ì„ ì¶”ê°€í•˜ì—¬ NAV ë³€í™”ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤. (ì „ì¼ ì¢…ê°€ ê¸°ì¤€)")

                # ì‹œë®¬ë ˆì´ì…˜ ì„¤ì •
                col_sim_settings1, col_sim_settings2 = st.columns(2)

                with col_sim_settings1:
                    sim_days = st.slider("ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„ (ì¼)", min_value=5, max_value=90, value=30, step=5)

                with col_sim_settings2:
                    # ì¶”ê°€ í˜„ê¸ˆ íˆ¬ì… ì˜µì…˜
                    use_additional_cash = st.checkbox("ğŸ’° ì¶”ê°€ í˜„ê¸ˆ íˆ¬ì…", value=False,
                                                      help="ë¹„ì¤‘ ìƒí–¥ ì‹œ ê¸°ì¡´ NAVë¥¼ ìœ ì§€í•˜ë©´ì„œ ì¶”ê°€ ìê¸ˆì„ íˆ¬ì…í•©ë‹ˆë‹¤.")

                additional_cash_krw = 0
                if use_additional_cash:
                    st.markdown("#### ğŸ’µ ì¶”ê°€ í˜„ê¸ˆ íˆ¬ì… ì„¤ì •")

                    cash_input_col1, cash_input_col2 = st.columns(2)
                    with cash_input_col1:
                        additional_cash_krw = st.number_input(
                            "ì¶”ê°€ íˆ¬ì… ê¸ˆì•¡ (KRW)",
                            min_value=0,
                            max_value=100_000_000_000,  # 1000ì–µ
                            value=0,
                            step=100_000_000,  # 1ì–µ ë‹¨ìœ„
                            format="%d",
                            help="ì¶”ê°€ë¡œ íˆ¬ì…í•  í˜„ê¸ˆ (ì›í™”)"
                        )
                    with cash_input_col2:
                        if additional_cash_krw > 0:
                            new_total_nav = total_mv + additional_cash_krw
                            st.metric("ìƒˆë¡œìš´ ì´ NAV", f"â‚©{new_total_nav:,.0f}")
                            st.caption(f"ê¸°ì¡´ NAV: â‚©{total_mv:,.0f} + ì¶”ê°€: â‚©{additional_cash_krw:,.0f}")

                st.markdown("---")

                # ë‘ ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
                col_existing, col_new = st.columns(2)

                with col_existing:
                    st.markdown("#### ğŸ“ˆ ê¸°ì¡´ ì¢…ëª© ë¹„ì¤‘ ì¡°ì ˆ")
                    st.caption("ë¹„ì¤‘ì„ ì¡°ì ˆí•  ì¢…ëª©ì„ ì„ íƒí•˜ê³  ìƒˆë¡œìš´ ë¹„ì¤‘(%)ì„ ì…ë ¥í•˜ì„¸ìš”.")

                    # ê¸°ì¡´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ (ìƒìœ„ 20ê°œ)
                    top_20 = holdings.sort_values("Weight", ascending=False).head(20)

                    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
                    if "weight_adjustments" not in st.session_state:
                        st.session_state.weight_adjustments = {}

                    # ì¢…ëª©ë³„ ìŠ¬ë¼ì´ë”
                    weight_adjustments = {}
                    for idx, row in top_20.iterrows():
                        ticker = row["YF_Symbol"]
                        current_weight = row["Weight"] * 100  # %ë¡œ ë³€í™˜
                        label = f"{row['ì¢…ëª©ëª…']} ({ticker})"

                        new_weight = st.number_input(
                            label,
                            min_value=0.0,
                            max_value=100.0,
                            value=float(current_weight),
                            step=0.5,
                            format="%.2f",
                            key=f"weight_{ticker}",
                            help=f"í˜„ì¬ ë¹„ì¤‘: {current_weight:.2f}%"
                        )
                        if abs(new_weight - current_weight) > 0.01:
                            weight_adjustments[ticker] = new_weight / 100  # ë¹„ìœ¨ë¡œ ë³€í™˜

                with col_new:
                    st.markdown("#### â• ì‹ ê·œ ì¢…ëª© ì¶”ê°€")
                    st.caption("ì¶”ê°€í•  ì¢…ëª© í‹°ì»¤, ë§ˆì¼“, ë¹„ì¤‘(%)ì„ ì…ë ¥í•˜ì„¸ìš”.")

                    # ë§ˆì¼“ ì˜µì…˜
                    market_options = {
                        "US": "ë¯¸êµ­ (ê¸°ë³¸)",
                        "JP": "ì¼ë³¸ (.T)",
                        "HK": "í™ì½© (.HK)",
                        "KR": "í•œêµ­ (.KS)"
                    }

                    # ì‹ ê·œ ì¢…ëª© ì…ë ¥ (ìµœëŒ€ 5ê°œ)
                    new_positions = []
                    for i in range(5):
                        c1, c2, c3 = st.columns([2, 1, 1])
                        with c1:
                            new_ticker_raw = st.text_input(
                                f"í‹°ì»¤ {i+1}",
                                value="",
                                placeholder="ì˜ˆ: AAPL, 7203, 0700",
                                key=f"new_ticker_{i}"
                            ).upper().strip()
                        with c2:
                            new_market = st.selectbox(
                                f"ë§ˆì¼“ {i+1}",
                                options=list(market_options.keys()),
                                format_func=lambda x: market_options[x],
                                key=f"new_market_{i}"
                            )
                        with c3:
                            new_weight_pct = st.number_input(
                                f"ë¹„ì¤‘ % {i+1}",
                                min_value=0.0,
                                max_value=50.0,
                                value=0.0,
                                step=0.5,
                                format="%.2f",
                                key=f"new_weight_{i}"
                            )

                        # í‹°ì»¤ ë³€í™˜ (ë§ˆì¼“ì— ë”°ë¼ suffix ì¶”ê°€)
                        if new_ticker_raw and new_weight_pct > 0:
                            if new_market == "JP":
                                final_ticker = f"{new_ticker_raw}.T" if not new_ticker_raw.endswith(".T") else new_ticker_raw
                            elif new_market == "HK":
                                # í™ì½©ì€ 4ìë¦¬ ìˆ«ìë¡œ íŒ¨ë”©
                                if new_ticker_raw.isdigit():
                                    final_ticker = f"{new_ticker_raw.zfill(4)}.HK"
                                elif not new_ticker_raw.endswith(".HK"):
                                    final_ticker = f"{new_ticker_raw}.HK"
                                else:
                                    final_ticker = new_ticker_raw
                            elif new_market == "KR":
                                final_ticker = f"{new_ticker_raw}.KS" if not new_ticker_raw.endswith(".KS") else new_ticker_raw
                            else:
                                final_ticker = new_ticker_raw

                            new_positions.append({
                                "ticker": final_ticker,
                                "weight": new_weight_pct / 100,
                                "market": new_market
                            })

                    if new_positions:
                        st.caption("**ì¶”ê°€ë  ì¢…ëª©:**")
                        for pos in new_positions:
                            st.caption(f"  â€¢ {pos['ticker']} ({pos['weight']*100:.1f}%)")

                st.markdown("---")

                # ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ë²„íŠ¼
                if st.button("ğŸš€ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰", type="primary", use_container_width=True):
                    if not weight_adjustments and not new_positions and additional_cash_krw == 0:
                        st.warning("ë¹„ì¤‘ì„ ì¡°ì ˆí•˜ê±°ë‚˜ ì‹ ê·œ ì¢…ëª©ì„ ì¶”ê°€í•˜ê±°ë‚˜ ì¶”ê°€ í˜„ê¸ˆì„ íˆ¬ì…í•´ì£¼ì„¸ìš”.")
                    else:
                        # ì‹œë®¬ë ˆì´ì…˜ NAV ê²°ì • (ì¶”ê°€ í˜„ê¸ˆ í¬í•¨ ì—¬ë¶€)
                        sim_base_nav = total_mv + additional_cash_krw if use_additional_cash else total_mv

                        with st.spinner("ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì¤‘..."):
                            result = simulate_portfolio_nav(
                                holdings_df=holdings,
                                weight_adjustments=weight_adjustments,
                                new_positions=new_positions,
                                base_nav=sim_base_nav,
                                simulation_days=sim_days,
                                additional_cash=additional_cash_krw if use_additional_cash else 0,
                                original_nav=total_mv
                            )

                        if result is None:
                            st.error("ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì‹¤íŒ¨. ê°€ê²© ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            st.success("ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ!")

                            # ì¶”ê°€ í˜„ê¸ˆ íˆ¬ì… ì‹œ ì•ˆë‚´ ë©”ì‹œì§€
                            if use_additional_cash and additional_cash_krw > 0:
                                st.info(f"ğŸ’° **ì¶”ê°€ í˜„ê¸ˆ íˆ¬ì… ëª¨ë“œ**: ê¸°ì¡´ NAV â‚©{total_mv:,.0f} + ì¶”ê°€ í˜„ê¸ˆ â‚©{additional_cash_krw:,.0f} = ìƒˆ NAV â‚©{sim_base_nav:,.0f}")

                            # ê²°ê³¼ í‘œì‹œ
                            st.markdown("### ğŸ“Š ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼")

                            # NAV ë¹„êµ ì°¨íŠ¸
                            fig_nav = go.Figure()
                            fig_nav.add_trace(go.Scatter(
                                x=result["original_nav"].index,
                                y=result["original_nav"].values,
                                mode="lines",
                                name="ì›ë˜ í¬íŠ¸í´ë¦¬ì˜¤",
                                line=dict(color="#6366f1", width=2)
                            ))
                            fig_nav.add_trace(go.Scatter(
                                x=result["sim_nav"].index,
                                y=result["sim_nav"].values,
                                mode="lines",
                                name=f"ì‹œë®¬ë ˆì´ì…˜ í¬íŠ¸í´ë¦¬ì˜¤{' (ì¶”ê°€ í˜„ê¸ˆ)' if additional_cash_krw > 0 else ''}",
                                line=dict(color="#f97316", width=2, dash="dash")
                            ))
                            fig_nav.update_layout(
                                title="í¬íŠ¸í´ë¦¬ì˜¤ NAV ë¹„êµ",
                                xaxis_title="ë‚ ì§œ",
                                yaxis_title="NAV (KRW)",
                                yaxis_tickformat=",",
                                legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.01),
                                hovermode="x unified"
                            )
                            st.plotly_chart(fig_nav, use_container_width=True)

                            # ì„±ê³¼ ë¹„êµ ë©”íŠ¸ë¦­
                            orig_final = result["original_nav"].iloc[-1]
                            sim_final = result["sim_nav"].iloc[-1]
                            orig_return = (orig_final / total_mv - 1) * 100
                            sim_return = (sim_final / sim_base_nav - 1) * 100
                            nav_diff = sim_final - orig_final
                            return_diff = sim_return - orig_return

                            m1, m2, m3, m4 = st.columns(4)
                            m1.metric("ì›ë˜ NAV", f"{orig_final:,.0f}")
                            m2.metric("ì‹œë®¬ë ˆì´ì…˜ NAV", f"{sim_final:,.0f}", delta=f"{nav_diff:,.0f}")
                            m3.metric("ì›ë˜ ìˆ˜ìµë¥ ", f"{orig_return:.2f}%")
                            m4.metric("ì‹œë®¬ë ˆì´ì…˜ ìˆ˜ìµë¥ ", f"{sim_return:.2f}%", delta=f"{return_diff:+.2f}%")

                            # ë³€ë™ì„± ë¹„êµ
                            st.markdown("### ğŸ“‰ ë³€ë™ì„± ë¹„êµ (30ì¼ ê¸°ì¤€)")

                            with st.spinner("ë³€ë™ì„± ê³„ì‚° ì¤‘..."):
                                orig_vol = calculate_portfolio_volatility(result["original_weights"], lookback_days=30)
                                sim_vol = calculate_portfolio_volatility(result["sim_weights"], lookback_days=30)

                            if orig_vol and sim_vol:
                                vol_diff = sim_vol["annual_volatility"] - orig_vol["annual_volatility"]
                                mdd_diff = sim_vol["max_drawdown"] - orig_vol["max_drawdown"]
                                var95_diff = sim_vol["var_95"] - orig_vol["var_95"]

                                v1, v2, v3, v4 = st.columns(4)
                                v1.metric("ì›ë˜ ë³€ë™ì„± (ì—°ìœ¨)", f"{orig_vol['annual_volatility']:.2%}")
                                v2.metric("ì‹œë®¬ë ˆì´ì…˜ ë³€ë™ì„±", f"{sim_vol['annual_volatility']:.2%}",
                                         delta=f"{vol_diff:+.2%}",
                                         delta_color="inverse")  # ë³€ë™ì„± ì¦ê°€ëŠ” ë¹¨ê°„ìƒ‰
                                v3.metric("ì›ë˜ VaR 95%", f"{orig_vol['var_95']:.2%}")
                                v4.metric("ì‹œë®¬ë ˆì´ì…˜ VaR 95%", f"{sim_vol['var_95']:.2%}",
                                         delta=f"{var95_diff:+.2%}",
                                         delta_color="inverse")

                                v5, v6, v7, v8 = st.columns(4)
                                v5.metric("ì›ë˜ MDD", f"{orig_vol['max_drawdown']:.2%}")
                                v6.metric("ì‹œë®¬ë ˆì´ì…˜ MDD", f"{sim_vol['max_drawdown']:.2%}",
                                         delta=f"{mdd_diff:+.2%}",
                                         delta_color="inverse")
                                v7.metric("ì›ë˜ VaR 99%", f"{orig_vol['var_99']:.2%}")
                                v8.metric("ì‹œë®¬ë ˆì´ì…˜ VaR 99%", f"{sim_vol['var_99']:.2%}")

                                # ë¦¬ìŠ¤í¬/ë¦¬í„´ ìš”ì•½
                                st.markdown("#### ë¦¬ìŠ¤í¬-ë¦¬í„´ ìš”ì•½")
                                orig_sharpe = orig_return / (orig_vol['annual_volatility'] * 100) if orig_vol['annual_volatility'] > 0 else 0
                                sim_sharpe = sim_return / (sim_vol['annual_volatility'] * 100) if sim_vol['annual_volatility'] > 0 else 0
                                sharpe_diff = sim_sharpe - orig_sharpe

                                rs1, rs2, rs3 = st.columns(3)
                                rs1.metric("ì›ë˜ ìƒ¤í”„ë¹„ìœ¨", f"{orig_sharpe:.3f}")
                                rs2.metric("ì‹œë®¬ë ˆì´ì…˜ ìƒ¤í”„ë¹„ìœ¨", f"{sim_sharpe:.3f}", delta=f"{sharpe_diff:+.3f}")
                                rs3.metric("ë¦¬ìŠ¤í¬ ì¡°ì • íš¨ê³¼",
                                          "ê°œì„ " if sharpe_diff > 0 else "ì•…í™”" if sharpe_diff < 0 else "ë™ì¼",
                                          delta=f"{sharpe_diff:+.3f}")
                            else:
                                st.warning("ë³€ë™ì„±ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                            # ë¹„ì¤‘ ë³€ê²½ ìš”ì•½
                            st.markdown("### ğŸ“‹ ë¹„ì¤‘ ë³€ê²½ ìš”ì•½")

                            # ë³€ê²½ëœ ë¹„ì¤‘ í…Œì´ë¸”
                            changes = []
                            for ticker, new_w in result["sim_weights"].items():
                                orig_w = result["original_weights"].get(ticker, 0)
                                if abs(new_w - orig_w) > 0.0001:
                                    # ì¢…ëª©ëª… ì°¾ê¸°
                                    name_row = holdings[holdings["YF_Symbol"] == ticker]
                                    name = name_row["ì¢…ëª©ëª…"].values[0] if len(name_row) > 0 else ticker
                                    changes.append({
                                        "í‹°ì»¤": ticker,
                                        "ì¢…ëª©ëª…": name,
                                        "ì›ë˜ ë¹„ì¤‘": orig_w,
                                        "ë³€ê²½ ë¹„ì¤‘": new_w,
                                        "ë³€ê²½í­": new_w - orig_w
                                    })

                            if changes:
                                df_changes = pd.DataFrame(changes)
                                df_changes = df_changes.sort_values("ë³€ê²½í­", ascending=False)
                                st.dataframe(
                                    df_changes.style.format({
                                        "ì›ë˜ ë¹„ì¤‘": "{:.2%}",
                                        "ë³€ê²½ ë¹„ì¤‘": "{:.2%}",
                                        "ë³€ê²½í­": "{:+.2%}"
                                    }).background_gradient(subset=["ë³€ê²½í­"], cmap="RdYlGn", vmin=-0.1, vmax=0.1),
                                    use_container_width=True
                                )
                            else:
                                st.info("ë¹„ì¤‘ ë³€ê²½ ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")

                            # ë§¤ë§¤ ì£¼ìˆ˜ ê³„ì‚°
                            st.markdown("### ğŸ›’ ë§¤ë§¤ ì£¼ë¬¸ (Trade Orders)")
                            if use_additional_cash and additional_cash_krw > 0:
                                st.caption(f"ëª©í‘œ ë¹„ì¤‘ ë‹¬ì„±ì„ ìœ„í•´ ë§¤ë§¤í•´ì•¼ í•˜ëŠ” ì£¼ìˆ˜ì…ë‹ˆë‹¤. (ìƒˆ NAV â‚©{sim_base_nav:,.0f} ê¸°ì¤€, ê° êµ­ê°€ë³„ ìµœì¢… ì˜ì—…ì¼ ì¢…ê°€)")
                            else:
                                st.caption("ëª©í‘œ ë¹„ì¤‘ ë‹¬ì„±ì„ ìœ„í•´ ë§¤ë§¤í•´ì•¼ í•˜ëŠ” ì£¼ìˆ˜ì…ë‹ˆë‹¤. (ê° êµ­ê°€ë³„ ìµœì¢… ì˜ì—…ì¼ ì¢…ê°€ ê¸°ì¤€)")

                            with st.spinner("ë§¤ë§¤ ì£¼ìˆ˜ ê³„ì‚° ì¤‘..."):
                                trades = calculate_trade_shares(
                                    result["original_weights"],
                                    result["sim_weights"],
                                    sim_base_nav,  # ì¶”ê°€ í˜„ê¸ˆ í¬í•¨ëœ NAV ì‚¬ìš©
                                    holdings,
                                    new_positions,
                                    original_nav=total_mv,
                                    additional_cash=additional_cash_krw if use_additional_cash else 0
                                )

                            if trades:
                                df_trades = pd.DataFrame(trades)

                                # ë§¤ìˆ˜/ë§¤ë„ ë¶„ë¦¬
                                buy_trades = df_trades[df_trades["ë§¤ë§¤"] == "ë§¤ìˆ˜"].copy()
                                sell_trades = df_trades[df_trades["ë§¤ë§¤"] == "ë§¤ë„"].copy()

                                col_buy, col_sell = st.columns(2)

                                with col_buy:
                                    st.markdown("#### ğŸŸ¢ ë§¤ìˆ˜ ì£¼ë¬¸")
                                    if not buy_trades.empty:
                                        buy_display = buy_trades[["í‹°ì»¤", "ì¢…ëª©ëª…", "ì£¼ìˆ˜", "í˜„ì§€í†µí™”ê°€ê²©", "í†µí™”", "ë§¤ë§¤ê¸ˆì•¡(KRW)"]].copy()
                                        buy_display = buy_display.sort_values("ë§¤ë§¤ê¸ˆì•¡(KRW)", ascending=False)
                                        st.dataframe(
                                            buy_display.style.format({
                                                "ì£¼ìˆ˜": "{:,.0f}",
                                                "í˜„ì§€í†µí™”ê°€ê²©": "{:,.2f}",
                                                "ë§¤ë§¤ê¸ˆì•¡(KRW)": "{:,.0f}"
                                            }),
                                            use_container_width=True
                                        )
                                        total_buy_krw = buy_trades["ë§¤ë§¤ê¸ˆì•¡(KRW)"].sum()
                                        st.metric("ì´ ë§¤ìˆ˜ ê¸ˆì•¡ (KRW)", f"{total_buy_krw:,.0f}")
                                    else:
                                        st.info("ë§¤ìˆ˜í•  ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

                                with col_sell:
                                    st.markdown("#### ğŸ”´ ë§¤ë„ ì£¼ë¬¸")
                                    if not sell_trades.empty:
                                        sell_display = sell_trades[["í‹°ì»¤", "ì¢…ëª©ëª…", "ì£¼ìˆ˜", "í˜„ì§€í†µí™”ê°€ê²©", "í†µí™”", "ë§¤ë§¤ê¸ˆì•¡(KRW)"]].copy()
                                        sell_display = sell_display.sort_values("ë§¤ë§¤ê¸ˆì•¡(KRW)", ascending=False)
                                        st.dataframe(
                                            sell_display.style.format({
                                                "ì£¼ìˆ˜": "{:,.0f}",
                                                "í˜„ì§€í†µí™”ê°€ê²©": "{:,.2f}",
                                                "ë§¤ë§¤ê¸ˆì•¡(KRW)": "{:,.0f}"
                                            }),
                                            use_container_width=True
                                        )
                                        total_sell_krw = sell_trades["ë§¤ë§¤ê¸ˆì•¡(KRW)"].sum()
                                        st.metric("ì´ ë§¤ë„ ê¸ˆì•¡ (KRW)", f"{total_sell_krw:,.0f}")
                                    else:
                                        st.info("ë§¤ë„í•  ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

                                # ì „ì²´ ë§¤ë§¤ ìƒì„¸ í…Œì´ë¸”
                                with st.expander("ğŸ“Š ì „ì²´ ë§¤ë§¤ ìƒì„¸ ë³´ê¸°"):
                                    df_trades_display = df_trades[[
                                        "í‹°ì»¤", "ì¢…ëª©ëª…", "ë§¤ë§¤", "ì£¼ìˆ˜", "í˜„ì§€í†µí™”ê°€ê²©", "í†µí™”",
                                        "ì›ë˜ë¹„ì¤‘", "ëª©í‘œë¹„ì¤‘", "ë¹„ì¤‘ë³€í™”", "ë§¤ë§¤ê¸ˆì•¡(í˜„ì§€)", "ë§¤ë§¤ê¸ˆì•¡(KRW)"
                                    ]].copy()
                                    df_trades_display = df_trades_display.sort_values("ë§¤ë§¤ê¸ˆì•¡(KRW)", ascending=False)

                                    st.dataframe(
                                        df_trades_display.style.format({
                                            "ì£¼ìˆ˜": "{:,.0f}",
                                            "í˜„ì§€í†µí™”ê°€ê²©": "{:,.2f}",
                                            "ì›ë˜ë¹„ì¤‘": "{:.2%}",
                                            "ëª©í‘œë¹„ì¤‘": "{:.2%}",
                                            "ë¹„ì¤‘ë³€í™”": "{:+.2%}",
                                            "ë§¤ë§¤ê¸ˆì•¡(í˜„ì§€)": "{:,.2f}",
                                            "ë§¤ë§¤ê¸ˆì•¡(KRW)": "{:,.0f}"
                                        }),
                                        use_container_width=True
                                    )

                                    # ìˆœ í˜„ê¸ˆ íë¦„
                                    total_buy = buy_trades["ë§¤ë§¤ê¸ˆì•¡(KRW)"].sum() if not buy_trades.empty else 0
                                    total_sell = sell_trades["ë§¤ë§¤ê¸ˆì•¡(KRW)"].sum() if not sell_trades.empty else 0
                                    net_cash = total_sell - total_buy

                                    st.markdown("---")
                                    nc1, nc2, nc3 = st.columns(3)
                                    nc1.metric("ì´ ë§¤ìˆ˜", f"â‚©{total_buy:,.0f}")
                                    nc2.metric("ì´ ë§¤ë„", f"â‚©{total_sell:,.0f}")
                                    nc3.metric("ìˆœ í˜„ê¸ˆ íë¦„", f"â‚©{net_cash:,.0f}",
                                              delta="í˜„ê¸ˆ ìœ ì…" if net_cash > 0 else "í˜„ê¸ˆ ìœ ì¶œ" if net_cash < 0 else "ê· í˜•")
                            else:
                                st.info("ë§¤ë§¤í•  ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

                            # ì„¹í„° ë¹„ì¤‘ ë¹„êµ
                            st.markdown("### ğŸ§­ ì„¹í„° ë¹„ì¤‘ ë¹„êµ")

                            sector_map = result.get("sector_map", {})

                            # ì›ë˜ í¬íŠ¸í´ë¦¬ì˜¤ ì„¹í„° ë¹„ì¤‘
                            orig_sector_weights = {}
                            for ticker, weight in result["original_weights"].items():
                                sector = sector_map.get(ticker, "Unknown")
                                orig_sector_weights[sector] = orig_sector_weights.get(sector, 0) + weight

                            # ì‹œë®¬ë ˆì´ì…˜ í¬íŠ¸í´ë¦¬ì˜¤ ì„¹í„° ë¹„ì¤‘
                            sim_sector_weights = {}
                            for ticker, weight in result["sim_weights"].items():
                                sector = sector_map.get(ticker, "Unknown")
                                sim_sector_weights[sector] = sim_sector_weights.get(sector, 0) + weight

                            # ëª¨ë“  ì„¹í„° í•©ì¹˜ê¸°
                            all_sectors_sim = sorted(set(orig_sector_weights.keys()) | set(sim_sector_weights.keys()))

                            sector_comparison = []
                            for sector in all_sectors_sim:
                                orig_w = orig_sector_weights.get(sector, 0)
                                sim_w = sim_sector_weights.get(sector, 0)
                                sector_comparison.append({
                                    "ì„¹í„°": sector,
                                    "ì›ë˜ ë¹„ì¤‘": orig_w,
                                    "ì‹œë®¬ë ˆì´ì…˜ ë¹„ì¤‘": sim_w,
                                    "ë³€ê²½í­": sim_w - orig_w
                                })

                            df_sector_comp = pd.DataFrame(sector_comparison)
                            df_sector_comp = df_sector_comp.sort_values("ì‹œë®¬ë ˆì´ì…˜ ë¹„ì¤‘", ascending=False)

                            # ì„¹í„° ë¹„ì¤‘ ì°¨íŠ¸
                            col_sector1, col_sector2 = st.columns(2)

                            with col_sector1:
                                fig_sector_orig = go.Figure(data=go.Pie(
                                    labels=list(orig_sector_weights.keys()),
                                    values=list(orig_sector_weights.values()),
                                    hole=0.4,
                                    title="ì›ë˜ í¬íŠ¸í´ë¦¬ì˜¤"
                                ))
                                fig_sector_orig.update_traces(textinfo="percent+label")
                                st.plotly_chart(fig_sector_orig, use_container_width=True)

                            with col_sector2:
                                fig_sector_sim = go.Figure(data=go.Pie(
                                    labels=list(sim_sector_weights.keys()),
                                    values=list(sim_sector_weights.values()),
                                    hole=0.4,
                                    title="ì‹œë®¬ë ˆì´ì…˜ í¬íŠ¸í´ë¦¬ì˜¤"
                                ))
                                fig_sector_sim.update_traces(textinfo="percent+label")
                                st.plotly_chart(fig_sector_sim, use_container_width=True)

                            # ì„¹í„° ë¹„ì¤‘ ë³€í™” ë°” ì°¨íŠ¸
                            df_sector_diff = df_sector_comp[df_sector_comp["ë³€ê²½í­"].abs() > 0.0001].copy()
                            if not df_sector_diff.empty:
                                colors_sector = np.where(df_sector_diff["ë³€ê²½í­"].values >= 0, "#16a34a", "#dc2626")
                                fig_sector_diff = go.Figure(data=go.Bar(
                                    x=df_sector_diff["ì„¹í„°"],
                                    y=df_sector_diff["ë³€ê²½í­"],
                                    marker_color=colors_sector,
                                    text=[f"{v:+.1%}" for v in df_sector_diff["ë³€ê²½í­"]],
                                    textposition="auto"
                                ))
                                fig_sector_diff.update_layout(
                                    title="ì„¹í„° ë¹„ì¤‘ ë³€í™”",
                                    yaxis_tickformat=".1%",
                                    xaxis_title="",
                                    yaxis_title="ë¹„ì¤‘ ë³€í™”"
                                )
                                st.plotly_chart(fig_sector_diff, use_container_width=True)

                            # ì„¹í„° ë¹„ì¤‘ í…Œì´ë¸”
                            st.dataframe(
                                df_sector_comp.style.format({
                                    "ì›ë˜ ë¹„ì¤‘": "{:.2%}",
                                    "ì‹œë®¬ë ˆì´ì…˜ ë¹„ì¤‘": "{:.2%}",
                                    "ë³€ê²½í­": "{:+.2%}"
                                }).background_gradient(subset=["ë³€ê²½í­"], cmap="RdYlGn", vmin=-0.05, vmax=0.05),
                                use_container_width=True
                            )

                            # íŒ©í„° ìµìŠ¤í¬ì €
                            st.markdown("### ğŸ“ˆ íŒ©í„° ìµìŠ¤í¬ì € (Factor Exposure)")
                            st.caption("íŒ©í„° ETF ëŒ€ë¹„ ë² íƒ€ë¡œ ì¸¡ì •í•œ ìµìŠ¤í¬ì €ì…ë‹ˆë‹¤.")

                            with st.spinner("íŒ©í„° ìµìŠ¤í¬ì € ê³„ì‚° ì¤‘..."):
                                orig_exposure = calculate_factor_exposure(
                                    result["original_weights"],
                                    result["returns"],
                                    sim_days
                                )
                                sim_exposure = calculate_factor_exposure(
                                    result["sim_weights"],
                                    result["returns"],
                                    sim_days
                                )

                            if orig_exposure or sim_exposure:
                                all_factors = sorted(set(orig_exposure.keys()) | set(sim_exposure.keys()))

                                factor_comparison = []
                                for factor in all_factors:
                                    orig_exp = orig_exposure.get(factor, 0)
                                    sim_exp = sim_exposure.get(factor, 0)
                                    factor_comparison.append({
                                        "íŒ©í„°": factor,
                                        "ì›ë˜ ìµìŠ¤í¬ì €": orig_exp,
                                        "ì‹œë®¬ë ˆì´ì…˜ ìµìŠ¤í¬ì €": sim_exp,
                                        "ë³€ê²½í­": sim_exp - orig_exp
                                    })

                                df_factor = pd.DataFrame(factor_comparison)

                                # íŒ©í„° ìµìŠ¤í¬ì € ë¹„êµ ì°¨íŠ¸
                                fig_factor = go.Figure()
                                fig_factor.add_trace(go.Bar(
                                    name="ì›ë˜ í¬íŠ¸í´ë¦¬ì˜¤",
                                    x=df_factor["íŒ©í„°"],
                                    y=df_factor["ì›ë˜ ìµìŠ¤í¬ì €"],
                                    marker_color="#6366f1"
                                ))
                                fig_factor.add_trace(go.Bar(
                                    name="ì‹œë®¬ë ˆì´ì…˜ í¬íŠ¸í´ë¦¬ì˜¤",
                                    x=df_factor["íŒ©í„°"],
                                    y=df_factor["ì‹œë®¬ë ˆì´ì…˜ ìµìŠ¤í¬ì €"],
                                    marker_color="#f97316"
                                ))
                                fig_factor.update_layout(
                                    title="íŒ©í„° ìµìŠ¤í¬ì € ë¹„êµ (ë² íƒ€)",
                                    barmode="group",
                                    xaxis_title="",
                                    yaxis_title="ë² íƒ€",
                                    legend=dict(yanchor="top", y=0.99, xanchor="right", x=0.99)
                                )
                                st.plotly_chart(fig_factor, use_container_width=True)

                                # íŒ©í„° ìµìŠ¤í¬ì € í…Œì´ë¸”
                                st.dataframe(
                                    df_factor.style.format({
                                        "ì›ë˜ ìµìŠ¤í¬ì €": "{:.3f}",
                                        "ì‹œë®¬ë ˆì´ì…˜ ìµìŠ¤í¬ì €": "{:.3f}",
                                        "ë³€ê²½í­": "{:+.3f}"
                                    }).background_gradient(subset=["ë³€ê²½í­"], cmap="RdYlGn", vmin=-0.2, vmax=0.2),
                                    use_container_width=True
                                )
                            else:
                                st.warning("íŒ©í„° ìµìŠ¤í¬ì €ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

elif menu == "Total Portfolio (Team PNL)":
    st.subheader("ğŸ“Š Total Team Portfolio Dashboard")
    uploaded_file = st.sidebar.file_uploader("Upload 'Team_PNL.xlsx'", type=['xlsx'], key="pnl")
    
    if uploaded_file:
        df_pnl, df_pos, err = load_team_pnl_data(uploaded_file)
        if df_pnl is not None:
            common_idx = df_pnl.index.intersection(df_pos.index)
            common_cols = [c for c in df_pnl.columns if c in df_pos.columns]
            df_pnl = df_pnl.loc[common_idx, common_cols]
            df_pos = df_pos.loc[common_idx, common_cols]
            
            df_cum_pnl = df_pnl.cumsum()
            df_user_ret = df_cum_pnl.div(df_pos.replace(0, np.nan)).fillna(0)
            df_daily_ret = df_pnl.div(df_pos.replace(0, np.nan)).fillna(0)
            
            t1, t2, t3, t4, t5 = st.tabs(["ğŸ“ˆ Chart", "ğŸ“Š Analysis", "ğŸ”— Correlation", "ğŸŒ Cross Asset", "ğŸ§ª Simulation"])
            
            with t1:
                strat = st.selectbox("Select Strategy", df_user_ret.columns)
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=df_user_ret.index, y=df_user_ret[strat], name=strat, line=dict(width=2)))
                
                # Add Benchmarks
                bm_returns = download_benchmarks_all(df_pnl.index.min(), df_pnl.index.max())
                if not bm_returns.empty:
                    bm_cum = (1 + bm_returns).cumprod() - 1
                    for col in ['US', 'KR']:
                         if col in bm_cum.columns:
                            fig.add_trace(go.Scatter(x=bm_cum.index, y=bm_cum[col], name=f"{col} BM", line=dict(width=1, dash='dash')))
                st.plotly_chart(fig, use_container_width=True)
            
            with t2:
                stats = pd.DataFrame(index=df_daily_ret.columns)
                stats['Volatility'] = df_daily_ret.std() * np.sqrt(252)
                stats['Sharpe'] = (df_daily_ret.mean() / df_daily_ret.std() * np.sqrt(252)).fillna(0)
                stats['Win Rate'] = (df_daily_ret > 0).sum() / (df_daily_ret != 0).sum()
                
                # Profit Factor
                gp = df_daily_ret[df_daily_ret > 0].sum()
                gl = df_daily_ret[df_daily_ret < 0].sum().abs()
                stats['Profit Factor'] = (gp / gl).fillna(0)
                
                stats['MDD'] = ((1+df_daily_ret).cumprod() / (1+df_daily_ret).cumprod().cummax() - 1).min()
                stats['Total Return'] = df_user_ret.iloc[-1]
                
                disp = stats.copy()
                for c in disp.columns:
                    if c in ['Sharpe', 'Profit Factor']: disp[c] = disp[c].apply(lambda x: f"{x:.2f}")
                    else: disp[c] = disp[c].apply(lambda x: f"{x:.2%}")
                
                disp.insert(0, 'Strategy', disp.index)
                disp['Strategy'] = disp['Strategy'].apply(lambda x: x.split('_')[0])
                st.markdown(create_manual_html_table(disp), unsafe_allow_html=True)

            with t3:
                corr = df_daily_ret.corr()
                fig_corr = go.Figure(data=go.Heatmap(z=corr.values, x=corr.columns, y=corr.index, colorscale='RdBu', zmin=-1, zmax=1))
                fig_corr.update_layout(height=700)
                st.plotly_chart(fig_corr, use_container_width=True)
                
            with t4:
                df_assets = download_cross_assets(df_pnl.index.min(), df_pnl.index.max())
                if not df_assets.empty:
                    df_assets = df_assets.reindex(df_user_ret.index, method='ffill').pct_change().fillna(0)
                    comb = pd.concat([df_daily_ret, df_assets], axis=1).corr()
                    sub_corr = comb.loc[df_daily_ret.columns, df_assets.columns]
                    fig_cross = go.Figure(data=go.Heatmap(z=sub_corr.values, x=sub_corr.columns, y=sub_corr.index, colorscale='RdBu', zmin=-1, zmax=1))
                    st.plotly_chart(fig_cross, use_container_width=True)
                else: st.write("Data not available.")
            
            with t5:
                st.subheader("Simulation")
                c_in, c_out = st.columns([1,3])
                with c_in:
                    weights = {}
                    for col in df_daily_ret.columns:
                        weights[col] = st.slider(col, 0.0, 1.0, 1.0/len(df_daily_ret.columns), 0.05, key=f"sim_{col}")
                with c_out:
                    w_series = pd.Series(weights)
                    sim_daily = df_daily_ret.mul(w_series, axis=1).sum(axis=1)
                    sim_cum = (1 + sim_daily).cumprod() - 1
                    
                    fig_sim = go.Figure()
                    fig_sim.add_trace(go.Scatter(x=sim_cum.index, y=sim_cum, name="Simulated", line=dict(color='red')))
                    act_daily = df_pnl.sum(axis=1).div(df_pos.sum(axis=1)).fillna(0)
                    act_cum = (1 + act_daily).cumprod() - 1
                    fig_sim.add_trace(go.Scatter(x=act_cum.index, y=act_cum, name="Actual", line=dict(color='grey', dash='dot')))
                    st.plotly_chart(fig_sim, use_container_width=True)
        else: st.error(err)

elif menu == "Cash Equity Analysis":
    st.subheader("ğŸ“ˆ Cash Equity Portfolio Analysis")
    uploaded_file_ce = st.sidebar.file_uploader("Upload 'Holdings3.xlsx'", type=['xlsx'], key="ce")
    
    if uploaded_file_ce:
        with st.spinner("Processing Data & Fetching Factors..."):
            res = load_cash_equity_data(uploaded_file_ce)
            df_perf, df_last, df_contrib, country_daily, logs, err, _ = res
        
        if err: st.error(err)
        elif df_perf is not None:
            start_dt, end_dt = df_perf.index.min(), df_perf.index.max()
            bm_returns = download_benchmarks_all(start_dt, end_dt)
            factor_prices = download_factors(start_dt, end_dt, return_prices=True)
            
            view_opt = st.radio("Currency View", ["KRW", "Local Currency (USD Base)"], horizontal=True)

            max_perf_date = df_perf.index.max() if not df_perf.empty else pd.NaT
            max_hold_date = df_last['ê¸°ì¤€ì¼ì'].max() if df_last is not None else pd.NaT
            max_date = max_perf_date if pd.notna(max_perf_date) else max_hold_date
            if pd.notna(max_date):
                curr_hold = df_last[(df_last['ê¸°ì¤€ì¼ì'] == max_date) & (df_last['ì”ê³ ìˆ˜ëŸ‰'] > 0)]
            else:
                curr_hold = df_last[df_last['ì”ê³ ìˆ˜ëŸ‰'] > 0] if df_last is not None else pd.DataFrame()

            if 'Total_MV_KRW' in df_perf.columns and not df_perf.empty:
                curr_aum = df_perf.iloc[-1]['Total_MV_KRW']
            else:
                curr_aum = curr_hold['ì›í™”í‰ê°€ê¸ˆì•¡'].sum() if not curr_hold.empty else 0
            
            c1, c2, c3, c4 = st.columns(4)
            if df_perf.empty:
                c1.metric("Total Return (Hedged)", "N/A")
                c2.metric("Equity Return (Unhedged)", "N/A")
                c3.metric("Hedge Impact", "N/A")
                y_main = y_sub = None
                name_main = name_sub = None
                target_ret = pd.Series(dtype=float)
            elif view_opt == "KRW":
                last_day = df_perf.iloc[-1]
                c1.metric("Total Return (Hedged)", f"{last_day['Cum_Total_KRW']:.2%}")
                c2.metric("Equity Return (Unhedged)", f"{last_day['Cum_Equity_KRW']:.2%}")
                c3.metric("Hedge Impact", f"{(last_day['Cum_Total_KRW'] - last_day['Cum_Equity_KRW']):.2%}")
                y_main, y_sub = 'Cum_Total_KRW', 'Cum_Equity_KRW'
                name_main, name_sub = 'Total (Hedged)', 'Equity (KRW)'
                target_ret = df_perf['Ret_Total_KRW']
            else:
                last_day = df_perf.iloc[-1]
                c1.metric("Total Return (Hedged)", f"{last_day['Cum_Total_Local']:.2%}")
                c2.metric("Equity Return (Unhedged)", f"{last_day['Cum_Equity_Local']:.2%}")
                c3.metric("Hedge Impact", f"{(last_day['Cum_Total_Local'] - last_day['Cum_Equity_Local']):.2%}")
                y_main, y_sub = 'Cum_Total_Local', 'Cum_Equity_Local'
                name_main, name_sub = 'Total (Hedged)', 'Equity (Local/USD)'
                target_ret = df_perf['Ret_Total_Local']
            c4.metric("Current AUM", f"{curr_aum:,.0f} KRW")

            if not df_perf.empty and y_main:
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=df_perf.index, y=df_perf[y_main], name=name_main, line=dict(color='#2563eb', width=3)))
                if y_sub: fig.add_trace(go.Scatter(x=df_perf.index, y=df_perf[y_sub], name=name_sub, line=dict(color='#60a5fa', dash='dot')))
                
                if not bm_returns.empty:
                    bm_cum = (1 + bm_returns).cumprod() - 1
                    for col in ['US', 'KR', 'HK', 'JP']:
                        if col in bm_cum.columns:
                            fig.add_trace(go.Scatter(x=bm_cum.index, y=bm_cum[col], name=col+' BM', line=dict(width=1, dash='dash')))
                st.plotly_chart(fig, use_container_width=True)

            factor_returns = align_factor_returns(target_ret.index, factor_prices)

            st.markdown("#### ğŸ“Š Risk Metrics (Hedged Total Returns)")
            rows = []
            if view_opt == "KRW":
                port_label = "Portfolio (Hedged, KRW)"
            else:
                port_label = "Portfolio (Hedged, Local/USD)"
                st.caption("Local currency view uses total hedged returns (includes hedge PnL).")
            port_metrics = _calc_perf_metrics(target_ret)
            if port_metrics:
                rows.append({"Asset": port_label, **port_metrics})
            if not bm_returns.empty:
                bm_aligned = bm_returns.reindex(df_perf.index).dropna(how='all')
                for col in bm_aligned.columns:
                    metrics = _calc_perf_metrics(bm_aligned[col].dropna())
                    if metrics:
                        rows.append({"Asset": f"Benchmark {col}", **metrics})
            if rows:
                metrics_df = pd.DataFrame(rows)
                metric_order = [
                    "Total Return",
                    "CAGR",
                    "Annualized Volatility",
                    "Sharpe Ratio",
                    "Sortino Ratio",
                    "Max Drawdown",
                    "Calmar Ratio",
                    "Win Rate",
                ]
                metrics_df = metrics_df[["Asset"] + metric_order]
                disp = metrics_df.copy()
                percent_cols = ["Total Return", "CAGR", "Annualized Volatility", "Max Drawdown", "Win Rate"]
                ratio_cols = ["Sharpe Ratio", "Sortino Ratio", "Calmar Ratio"]
                for col in percent_cols:
                    disp[col] = disp[col].apply(lambda x: f"{x:.2%}" if pd.notnull(x) else "N/A")
                for col in ratio_cols:
                    disp[col] = disp[col].apply(lambda x: f"{x:.2f}" if pd.notnull(x) else "N/A")
                st.markdown(create_manual_html_table(disp, title="Risk Metrics vs Benchmarks"), unsafe_allow_html=True)
            else:
                st.write("Risk metrics not available.")

            t1, t2, t3, t4 = st.tabs(["Factor Risk & Attribution", "Selection Effect", "Holdings", "Beta Trend"])
            
            with t1:
                st.markdown(f"#### ğŸ§ª {FACTOR_TARGET_COUNT}-Factor Analysis (Risk & Attribution)")
                if not factor_returns.empty:
                    exposures, contrib, r2 = perform_factor_regression(target_ret, factor_returns)
                    
                    if exposures is not None:
                        st.write(f"**R-Squared:** {r2:.2f} (Explained by Factors)")
                        c_exp, c_attr = st.columns(2)
                        with c_exp:
                            st.markdown("**Factor Exposures (Beta)**")
                            fig_exp = px.bar(exposures, orientation='h', labels={'value':'Beta', 'index':'Factor'})
                            fig_exp.update_layout(showlegend=False)
                            st.plotly_chart(fig_exp, use_container_width=True)
                        with c_attr:
                            st.markdown("**Cumulative Factor Attribution**")
                            if not contrib.empty:
                                contrib_cum = (1 + contrib).cumprod() - 1
                                fig_attr = go.Figure()
                                for col in contrib_cum.columns:
                                    if col != 'Alpha' and col != 'Unexplained':
                                        fig_attr.add_trace(go.Scatter(x=contrib_cum.index, y=contrib_cum[col], name=col))
                                st.plotly_chart(fig_attr, use_container_width=True)
                        
                        st.markdown("#### ğŸ“… Monthly Factor Attribution")
                        m_contrib = contrib.resample('ME').apply(lambda x: (1+x).prod()-1)
                        m_contrib.index = m_contrib.index.strftime('%Y-%m')
                        fig_heat = go.Figure(data=go.Heatmap(
                            z=m_contrib.T.values, x=m_contrib.index, y=m_contrib.columns,
                            colorscale='RdBu', zmin=-0.03, zmax=0.03
                        ))
                        fig_heat.update_layout(height=500)
                        st.plotly_chart(fig_heat, use_container_width=True)
                    else:
                        st.write("Insufficient data to compute factor regression.")
                else: st.warning("Factor data download failed.")

            with t2:
                st.markdown("#### ğŸ’¹ Return Contribution")
                if df_contrib:
                    c_a, c_b = st.columns(2)
                    with c_a:
                        if not df_contrib['Country'].empty:
                            ctry_cont = df_contrib['Country'].groupby('Country')['Contrib_KRW'].sum().sort_values(ascending=False).reset_index()
                            st.plotly_chart(px.bar(ctry_cont, x='Contrib_KRW', y='Country', orientation='h', title="Contribution by Country", text_auto='.2%'))
                    with c_b:
                        if not df_contrib['Sector'].empty:
                            sec_cont = df_contrib['Sector'].groupby('ì„¹í„°')['Contrib_KRW'].sum().sort_values(ascending=False).reset_index()
                            st.plotly_chart(px.bar(sec_cont, x='Contrib_KRW', y='ì„¹í„°', orientation='h', title="Contribution by Sector", text_auto='.2%'))
                    
                    st.markdown("---")
                    st.markdown("#### ğŸ¥§ Current Allocation Breakdown")
                    if not curr_hold.empty:
                        st.plotly_chart(px.pie(curr_hold, values='ì›í™”í‰ê°€ê¸ˆì•¡', names='ì„¹í„°', title="Sector Allocation", hole=0.4), use_container_width=True)
                        st.plotly_chart(px.pie(curr_hold, values='ì›í™”í‰ê°€ê¸ˆì•¡', names='Country', title="Country Allocation", hole=0.4), use_container_width=True)

            with t3:
                pnl_df = df_last.sort_values('Final_PnL', ascending=False)[['ì¢…ëª©ëª…','ì„¹í„°','Country','Final_PnL']]
                cw, cl = st.columns(2)
                cw.success("Top Winners"); cw.dataframe(pnl_df.head(5).style.format({'Final_PnL':'{:,.0f}'}))
                cl.error("Top Losers"); cl.dataframe(pnl_df.tail(5).style.format({'Final_PnL':'{:,.0f}'}))
                with st.expander("Daily Data"): st.dataframe(df_perf)

            with t4:
                st.markdown("#### ğŸ“ˆ Rolling Beta Trend vs Benchmarks")
                if bm_returns.empty:
                    st.warning("Benchmark data download failed.")
                else:
                    beta_window = st.slider(
                        "Rolling window (trading days)",
                        min_value=20,
                        max_value=252,
                        value=60,
                        step=5,
                        key="beta_window",
                    )
                    beta_fig = go.Figure()
                    bench_map = {"SPX": "US", "Hang Seng": "HK", "Nikkei 225": "JP"}
                    for label, col in bench_map.items():
                        if col in bm_returns.columns:
                            beta_series = calculate_rolling_beta(target_ret, bm_returns[col], window=beta_window)
                            if not beta_series.empty:
                                beta_fig.add_trace(go.Scatter(x=beta_series.index, y=beta_series, name=f"{label} Beta"))
                    if beta_fig.data:
                        beta_fig.update_layout(yaxis_title="Beta", xaxis_title="Date")
                        st.plotly_chart(beta_fig, use_container_width=True)
                    else:
                        st.write("Insufficient data to compute rolling beta.")

                st.markdown("#### ğŸ§® Holdings-Weighted Beta (Latest)")
                bench_yf_map = {"S&P 500": "^GSPC", "Hang Seng": "^HSI", "Nikkei 225": "^N225", "KOSPI": "^KS11"}
                holdings_beta = calculate_holdings_beta(curr_hold, bench_yf_map, end_date=max_date)
                if holdings_beta:
                    beta_df = pd.Series(holdings_beta, name="Beta").sort_values().reset_index()
                    beta_df.columns = ["Benchmark", "Beta"]
                    fig_beta = px.bar(beta_df, x="Beta", y="Benchmark", orientation="h", title="Holdings-Weighted Beta")
                    fig_beta.update_layout(showlegend=False)
                    st.plotly_chart(fig_beta, use_container_width=True)
                else:
                    st.write("Insufficient data to compute holdings-weighted beta.")

elif menu == "ğŸ“‘ Weekly Report Generator":
    st.subheader("ğŸ“‘ Weekly Meeting Report Generator")
    uploaded_file_ce = st.sidebar.file_uploader("Upload 'Holdings3.xlsx' for Report", type=['xlsx'], key="rep")
    
    if uploaded_file_ce:
        with st.spinner("Generating Report Data..."):
            res = load_cash_equity_data(uploaded_file_ce)
            df_perf, df_last, df_contrib, country_daily, df_daily_stock, logs, err = res
            
        if err: st.error(err)
        elif df_perf is not None:
            view_opt = st.radio("Currency View", ["KRW (Hedged)", "Local (Hedged, USD base)"], horizontal=True, key="weekly_view_opt")
            if "Local" in view_opt:
                ret_col = "Ret_Total_Local"
                view_label = "Total Return (Local, hedged)"
            else:
                ret_col = "Ret_Total_KRW"
                view_label = "Total Return (KRW, hedged)"

            max_date = df_perf.index.max()
            report_date = st.date_input("Report Date", max_date)
            report_date = pd.to_datetime(report_date)
            
            factor_prices = download_factors(df_perf.index.min(), report_date, return_prices=True)
            factor_returns = align_factor_returns(df_perf[ret_col].index, factor_prices)
            _, factor_contrib, _ = perform_factor_regression(df_perf[ret_col], factor_returns)
            
            dates = {
                'WTD': df_perf.index[df_perf.index <= report_date][-1] - pd.to_timedelta(df_perf.index[df_perf.index <= report_date][-1].weekday(), unit='D'),
                'MTD': report_date.replace(day=1),
                'QTD': report_date.replace(month=((report_date.month-1)//3)*3+1, day=1),
                'YTD': report_date.replace(month=1, day=1)
            }
            
            global_px = download_global_indices(min(dates.values()), report_date)
            df_perf_cut = df_perf[df_perf.index <= report_date]
            df_stock_cut = df_daily_stock[df_daily_stock['ê¸°ì¤€ì¼ì'] <= report_date]
            if factor_contrib is not None:
                factor_contrib_cut = factor_contrib[factor_contrib.index <= report_date]
            else: factor_contrib_cut = None
            
            def calc_period_stats(start_dt, label, global_px):
                sub_perf = df_perf_cut[df_perf_cut.index >= start_dt]
                if sub_perf.empty: return None
                cum_ret = (1 + sub_perf[ret_col]).prod() - 1
                abs_pnl = sub_perf['Total_PnL_KRW'].sum()  # already includes hedge PnL in KRW
                sub_stock = df_stock_cut[df_stock_cut['ê¸°ì¤€ì¼ì'] >= start_dt]
                stock_contrib = sub_stock.groupby(['ì¢…ëª©ëª…', 'Ticker_ID'])['Contrib_KRW'].sum().reset_index()
                top5 = stock_contrib.sort_values('Contrib_KRW', ascending=False).head(5)
                bot5 = stock_contrib.sort_values('Contrib_KRW', ascending=True).head(5)
                ctry_contrib = sub_stock.groupby('Country')['Contrib_KRW'].sum().sort_values(ascending=False)
                sect_contrib = sub_stock.groupby('ì„¹í„°')['Contrib_KRW'].sum().sort_values(ascending=False)
                f_cont = pd.Series(dtype=float)
                if factor_contrib_cut is not None:
                    sub_f = factor_contrib_cut[factor_contrib_cut.index >= start_dt]
                    if not sub_f.empty:
                        f_cont = sub_f.apply(lambda x: (1+x).prod()-1).sort_values(ascending=False)
                idx_ret = pd.Series(dtype=float)
                sub_px = None
                if global_px is not None and not global_px.empty:
                    sub_px = global_px[(global_px.index >= start_dt) & (global_px.index <= report_date)]
                    sub_px = sub_px.ffill().bfill()
                    if not sub_px.empty:
                        idx_ret = sub_px.iloc[-1] / sub_px.iloc[0] - 1
                hedge_contrib = None
                hedge_pnl_krw = None
                if 'Hedge_PnL_KRW' in sub_perf.columns:
                    hedge_pnl_krw = sub_perf['Hedge_PnL_KRW'].sum()
                if ret_col == "Ret_Total_Local":
                    if 'Ret_Hedge_Local' in sub_perf.columns:
                        hedge_contrib = sub_perf['Ret_Hedge_Local'].fillna(0).sum()
                else:
                    if 'Hedge_PnL_KRW' in sub_perf.columns and 'Total_Prev_MV_KRW' in sub_perf.columns:
                        denom = sub_perf['Total_Prev_MV_KRW'].replace(0, np.nan)
                        hedge_contrib = (sub_perf['Hedge_PnL_KRW'] / denom).fillna(0).sum()
                portfolio_risk = _calc_risk_metrics(sub_perf[ret_col])
                benchmark_risk = {}
                if sub_px is not None and not sub_px.empty:
                    bench_ret = sub_px.pct_change().dropna(how='all')
                    for col in bench_ret.columns:
                        metrics = _calc_risk_metrics(bench_ret[col])
                        if metrics:
                            benchmark_risk[col] = metrics
                return {'label': label, 'ret': cum_ret, 'pnl': abs_pnl, 'top5': top5, 'bot5': bot5, 
                        'ctry': ctry_contrib, 'sect': sect_contrib, 'factor': f_cont, 'indices': idx_ret,
                        'hedge_contrib': hedge_contrib, 'hedge_pnl_krw': hedge_pnl_krw,
                        'risk': {'portfolio': portfolio_risk, 'benchmarks': benchmark_risk}}

            tabs = st.tabs(["Summary Report", "WTD", "MTD", "QTD", "YTD"])
            stats_res = {}
            for p in ['WTD', 'MTD', 'QTD', 'YTD']:
                stats_res[p] = calc_period_stats(dates[p], p, global_px)
                with tabs[list(dates.keys()).index(p) + 1]:
                    if stats_res[p]:
                        st.markdown(f"### {p} Performance ({dates[p].date()} ~ {report_date.date()})")
                        if not stats_res[p]['indices'].empty:
                            idx_df = stats_res[p]['indices'].sort_values(ascending=False).reset_index()
                            idx_df.columns = ['Index', 'Return']
                            idx_df['Return'] = idx_df['Return'].apply(lambda x: f"{x:.2%}")
                            st.markdown(create_manual_html_table(idx_df, title="Global Index Returns"), unsafe_allow_html=True)
                        c1, c2 = st.columns(2)
                        c1.metric(view_label, f"{stats_res[p]['ret']:.2%}")
                        c2.metric("PnL (KRW)", f"{stats_res[p]['pnl']:,.0f}")
                        st.markdown("#### Top Contributors")
                        c3, c4 = st.columns(2)
                        with c3: st.table(stats_res[p]['top5'][['ì¢…ëª©ëª…', 'Contrib_KRW']].style.format({'Contrib_KRW': '{:.2%}'}))
                        with c4: st.table(stats_res[p]['bot5'][['ì¢…ëª©ëª…', 'Contrib_KRW']].style.format({'Contrib_KRW': '{:.2%}'}))
                        st.markdown("#### Attribution Analysis")
                        col_a, col_b, col_c = st.columns(3)
                        with col_a:
                            st.markdown("**Country**")
                            st.dataframe(stats_res[p]['ctry'].to_frame().style.format('{:.2%}'))
                        with col_b:
                            st.markdown("**Sector**")
                            st.dataframe(stats_res[p]['sect'].to_frame().style.format('{:.2%}'))
                        with col_c:
                            st.markdown("**Factor**")
                            if not stats_res[p]['factor'].empty:
                                st.dataframe(stats_res[p]['factor'].to_frame(name='Contrib').style.format('{:.2%}'))
                            else: st.write("No factor data")
                        hedge_val = stats_res[p].get('hedge_contrib')
                        hedge_display = f"{hedge_val:.2%}" if hedge_val is not None else "N/A"
                        st.markdown("**Hedge Contribution**")
                        st.metric("Hedge Contribution (Return)", hedge_display)
                    else: st.write("No data.")

            with tabs[0]:
                st.markdown("### ğŸ“ Weekly Meeting Commentary")
                txt = f"**[Portfolio Weekly Update - {report_date.date()}]**\n\n"
                
                wtd = stats_res.get('WTD')
                if wtd:
                    txt += f"**1. WTD Performance:** {wtd['ret']:.2%} ({wtd['pnl']:,.0f} KRW)\n"
                    if not wtd['top5'].empty: txt += f"   - **Lead:** {wtd['top5'].iloc[0]['ì¢…ëª©ëª…']} (+{wtd['top5'].iloc[0]['Contrib_KRW']:.2%})\n"
                    if not wtd['factor'].empty: txt += f"   - **Factor:** Driven by {wtd['factor'].idxmax()} (+{wtd['factor'].max():.2%})\n"
                
                mtd = stats_res.get('MTD')
                if mtd: 
                    txt += f"**2. MTD:** {mtd['ret']:.2%}. Best Sector: {mtd['sect'].idxmax()}.\n"
                    if not mtd['factor'].empty: txt += f"   - Factor: {mtd['factor'].idxmax()} style worked well.\n"
                
                ytd = stats_res.get('YTD')
                if ytd: txt += f"**3. YTD:** {ytd['ret']:.2%}, Total PnL {ytd['pnl']:,.0f} KRW.\n"
                
                st.text_area("Copy this:", txt, height=300)

                st.markdown("#### ğŸ¤– AI-Generated Weekly Report")
                llm_choice = st.radio(
                    "Select LLM",
                    ["OpenAI (gpt-4o-mini)", "DeepSeek (deepseek-chat)"],
                    horizontal=True,
                    key="llm_choice_radio",
                )
                lang_choice = st.radio(
                    "ì–¸ì–´ / Language",
                    ["English", "í•œêµ­ì–´"],
                    horizontal=True,
                    key="ai_lang_choice_radio",
                )
                user_comment = st.text_area(
                    "Optional: Add your own market/positioning comments",
                    height=120,
                    key="ai_comment_input",
                )
                if st.button("Generate AI Report", key="ai_report_btn"):
                    provider = "deepseek" if "DeepSeek" in llm_choice else "openai"
                    try:
                        ai_text = generate_ai_weekly_report(
                            stats_res,
                            report_date,
                            user_comment,
                            provider=provider,
                            language=lang_choice,
                        )
                        st.text_area("AI Report", ai_text, height=400, key="ai_report_text")
                    except Exception as e:
                        st.error(f"Failed to generate AI report: {e}")

elif menu == "ğŸ“Š Swap Report Analysis":
    st.subheader("ğŸ“Š Swap Report Analysis (JMLNKWGE)")

    # SQLite DB ê²½ë¡œ - ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„
    possible_paths = [
        Path(__file__).resolve().parent / 'swap_reports.db',
        Path('/Users/hyejinha/Desktop/Workspace/Team/swap_reports.db'),
        Path.cwd() / 'swap_reports.db'
    ]

    SWAP_DB_FILE = None
    for p in possible_paths:
        if p.exists():
            SWAP_DB_FILE = p
            break

    def load_swap_data():
        """SQLite DBì—ì„œ Swap Report ë°ì´í„° ë¡œë“œ"""
        if SWAP_DB_FILE is None or not SWAP_DB_FILE.exists():
            return None, None, None, None

        conn = sqlite3.connect(SWAP_DB_FILE)

        # ë¦¬í¬íŠ¸ ëª©ë¡
        df_reports = pd.read_sql_query('''
            SELECT * FROM reports ORDER BY report_date DESC
        ''', conn)

        # Underlying ë°ì´í„°
        df_underlying = pd.read_sql_query('''
            SELECT u.*, r.report_date
            FROM underlying u
            JOIN reports r ON u.report_id = r.id
            ORDER BY r.report_date DESC, u.market_value_usd DESC
        ''', conn)

        # Overview ë°ì´í„°
        df_overview = pd.read_sql_query('''
            SELECT o.*, r.report_date
            FROM overview o
            JOIN reports r ON o.report_id = r.id
            ORDER BY r.report_date DESC
        ''', conn)

        # Und Summary ë°ì´í„°
        df_und = pd.read_sql_query('''
            SELECT us.*, r.report_date
            FROM und_summary us
            JOIN reports r ON us.report_id = r.id
            ORDER BY r.report_date DESC
        ''', conn)

        conn.close()
        return df_reports, df_underlying, df_overview, df_und

    # ë°ì´í„° ë¡œë“œ
    df_reports, df_underlying, df_overview, df_und = load_swap_data()

    if df_reports is None or df_reports.empty:
        st.warning("Swap Report ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.info("""
        **ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ë ¤ë©´:**
        1. Google Cloud Consoleì—ì„œ Gmail API ì„¤ì •
        2. credentials.json íŒŒì¼ì„ ì´ í´ë”ì— ì €ì¥
        3. í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰: `python swap_report_fetcher.py`
        """)

        # ìˆ˜ë™ ì—…ë¡œë“œ ì˜µì…˜
        st.markdown("---")
        st.markdown("### ğŸ“¤ ìˆ˜ë™ ì—…ë¡œë“œ")
        uploaded_file = st.file_uploader("Swap Report Excel íŒŒì¼ ì—…ë¡œë“œ", type=['xlsx'])

        if uploaded_file:
            try:
                xlsx = pd.ExcelFile(uploaded_file)
                st.success(f"íŒŒì¼ ë¡œë“œ ì„±ê³µ! ì‹œíŠ¸: {xlsx.sheet_names}")

                # ì‹œíŠ¸ ì„ íƒ
                selected_sheet = st.selectbox("ë¶„ì„í•  ì‹œíŠ¸ ì„ íƒ", xlsx.sheet_names)
                df_preview = pd.read_excel(xlsx, sheet_name=selected_sheet)
                st.dataframe(df_preview)
            except Exception as e:
                st.error(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    else:
        # ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
        st.success(f"ì´ {len(df_reports)}ê°œ ë¦¬í¬íŠ¸ ë¡œë“œë¨")

        # ë‚ ì§œ ë²”ìœ„
        df_reports['report_date'] = pd.to_datetime(df_reports['report_date'])
        min_date = df_reports['report_date'].min()
        max_date = df_reports['report_date'].max()
        st.caption(f"ë°ì´í„° ê¸°ê°„: {min_date.strftime('%Y-%m-%d')} ~ {max_date.strftime('%Y-%m-%d')}")

        # íƒ­ ìƒì„±
        tab_overview, tab_holdings, tab_pnl, tab_attribution = st.tabs([
            "ğŸ“ˆ Overview", "ğŸ“‹ Holdings", "ğŸ’° P&L Analysis", "ğŸ¯ Attribution"
        ])

        with tab_overview:
            st.markdown("### í¬íŠ¸í´ë¦¬ì˜¤ Overview")

            # ë‚ ì§œ ì„ íƒ
            available_dates = sorted(df_reports['report_date'].unique(), reverse=True)
            selected_date = st.selectbox(
                "ë¦¬í¬íŠ¸ ë‚ ì§œ ì„ íƒ",
                available_dates,
                format_func=lambda x: pd.Timestamp(x).strftime('%Y-%m-%d')
            )

            # ì„ íƒëœ ë‚ ì§œì˜ ë°ì´í„°
            df_date_underlying = df_underlying[
                pd.to_datetime(df_underlying['report_date']) == pd.Timestamp(selected_date)
            ].copy()

            if not df_date_underlying.empty:
                # ì£¼ìš” ì§€í‘œ
                total_mv = df_date_underlying['market_value_usd'].sum()
                total_pnl = df_date_underlying['pnl_usd'].sum()
                total_return = (df_date_underlying['pnl_usd'].sum() / total_mv * 100) if total_mv > 0 else 0

                c1, c2, c3, c4 = st.columns(4)
                c1.metric("Total NAV (USD)", f"${total_mv:,.0f}")
                c2.metric("Daily P&L (USD)", f"${total_pnl:,.0f}",
                         delta=f"{total_return:.2f}%")
                c3.metric("# Holdings", f"{len(df_date_underlying)}")
                c4.metric("Report Date", pd.Timestamp(selected_date).strftime('%Y-%m-%d'))

                # Top/Bottom Performers
                col_top, col_bottom = st.columns(2)

                with col_top:
                    st.markdown("#### ğŸŸ¢ Top 5 Performers")
                    top5 = df_date_underlying.nlargest(5, 'pnl_usd')[['ticker', 'name', 'pnl_usd', 'pnl_pct', 'contribution']]
                    st.dataframe(top5.style.format({
                        'pnl_usd': '${:,.0f}',
                        'pnl_pct': '{:.2f}%',
                        'contribution': '{:.2f}%'
                    }))

                with col_bottom:
                    st.markdown("#### ğŸ”´ Bottom 5 Performers")
                    bottom5 = df_date_underlying.nsmallest(5, 'pnl_usd')[['ticker', 'name', 'pnl_usd', 'pnl_pct', 'contribution']]
                    st.dataframe(bottom5.style.format({
                        'pnl_usd': '${:,.0f}',
                        'pnl_pct': '{:.2f}%',
                        'contribution': '{:.2f}%'
                    }))

        with tab_holdings:
            st.markdown("### ë³´ìœ  ì¢…ëª© ìƒì„¸")

            # ë‚ ì§œ ì„ íƒ
            selected_date_holdings = st.selectbox(
                "ë‚ ì§œ ì„ íƒ",
                available_dates,
                format_func=lambda x: pd.Timestamp(x).strftime('%Y-%m-%d'),
                key="holdings_date"
            )

            df_holdings = df_underlying[
                pd.to_datetime(df_underlying['report_date']) == pd.Timestamp(selected_date_holdings)
            ].copy()

            if not df_holdings.empty:
                # ë¹„ì¤‘ íŒŒì´ ì°¨íŠ¸
                col_chart, col_table = st.columns([1, 1])

                with col_chart:
                    # ìƒìœ„ 15ê°œ + ê¸°íƒ€
                    top_15 = df_holdings.nlargest(15, 'weight')
                    others_weight = df_holdings[~df_holdings['ticker'].isin(top_15['ticker'])]['weight'].sum()

                    labels = list(top_15['ticker']) + (['Others'] if others_weight > 0 else [])
                    values = list(top_15['weight']) + ([others_weight] if others_weight > 0 else [])

                    fig_pie = go.Figure(data=go.Pie(labels=labels, values=values, hole=0.4))
                    fig_pie.update_traces(textinfo='percent+label')
                    fig_pie.update_layout(title="Portfolio Weights")
                    st.plotly_chart(fig_pie, use_container_width=True)

                with col_table:
                    # ì„¹í„°ë³„ ë¹„ì¤‘
                    if 'sector' in df_holdings.columns and df_holdings['sector'].notna().any():
                        sector_weights = df_holdings.groupby('sector')['weight'].sum().sort_values(ascending=False)
                        fig_sector = go.Figure(data=go.Bar(
                            x=sector_weights.index,
                            y=sector_weights.values,
                            text=[f"{v:.1f}%" for v in sector_weights.values],
                            textposition='auto'
                        ))
                        fig_sector.update_layout(title="Sector Allocation", yaxis_tickformat=".1%")
                        st.plotly_chart(fig_sector, use_container_width=True)

                # ì „ì²´ Holdings í…Œì´ë¸”
                st.markdown("#### ì „ì²´ ë³´ìœ  ì¢…ëª©")
                display_cols = ['ticker', 'name', 'quantity', 'price', 'market_value_usd', 'weight', 'pnl_usd', 'pnl_pct', 'sector']
                display_cols = [c for c in display_cols if c in df_holdings.columns]
                st.dataframe(
                    df_holdings[display_cols].sort_values('weight', ascending=False).style.format({
                        'market_value_usd': '${:,.0f}',
                        'weight': '{:.2f}%',
                        'pnl_usd': '${:,.0f}',
                        'pnl_pct': '{:.2f}%',
                        'price': '${:,.2f}',
                        'quantity': '{:,.0f}'
                    }),
                    use_container_width=True
                )

        with tab_pnl:
            st.markdown("### P&L ë¶„ì„")

            # ì¼ë³„ P&L ê³„ì‚°
            daily_pnl = df_underlying.groupby('report_date').agg({
                'market_value_usd': 'sum',
                'pnl_usd': 'sum'
            }).reset_index()
            daily_pnl['report_date'] = pd.to_datetime(daily_pnl['report_date'])
            daily_pnl = daily_pnl.sort_values('report_date')
            daily_pnl['daily_return'] = daily_pnl['pnl_usd'] / daily_pnl['market_value_usd'].shift(1)
            daily_pnl['cumulative_pnl'] = daily_pnl['pnl_usd'].cumsum()
            daily_pnl['cumulative_return'] = (1 + daily_pnl['daily_return'].fillna(0)).cumprod() - 1

            # P&L ì°¨íŠ¸
            fig_pnl = go.Figure()
            fig_pnl.add_trace(go.Bar(
                x=daily_pnl['report_date'],
                y=daily_pnl['pnl_usd'],
                name='Daily P&L',
                marker_color=np.where(daily_pnl['pnl_usd'] >= 0, '#16a34a', '#dc2626')
            ))
            fig_pnl.update_layout(
                title="Daily P&L (USD)",
                xaxis_title="Date",
                yaxis_title="P&L ($)",
                yaxis_tickformat="$,.0f"
            )
            st.plotly_chart(fig_pnl, use_container_width=True)

            # ëˆ„ì  ìˆ˜ìµë¥  ì°¨íŠ¸
            fig_cum = go.Figure()
            fig_cum.add_trace(go.Scatter(
                x=daily_pnl['report_date'],
                y=daily_pnl['cumulative_return'],
                mode='lines+markers',
                name='Cumulative Return',
                line=dict(color='#6366f1', width=2)
            ))
            fig_cum.update_layout(
                title="Cumulative Return",
                xaxis_title="Date",
                yaxis_title="Return",
                yaxis_tickformat=".2%"
            )
            st.plotly_chart(fig_cum, use_container_width=True)

            # P&L í†µê³„
            st.markdown("#### P&L í†µê³„")
            total_pnl_all = daily_pnl['pnl_usd'].sum()
            avg_daily_pnl = daily_pnl['pnl_usd'].mean()
            win_rate = (daily_pnl['pnl_usd'] > 0).sum() / len(daily_pnl) * 100 if len(daily_pnl) > 0 else 0
            max_pnl = daily_pnl['pnl_usd'].max()
            min_pnl = daily_pnl['pnl_usd'].min()

            s1, s2, s3, s4, s5 = st.columns(5)
            s1.metric("Total P&L", f"${total_pnl_all:,.0f}")
            s2.metric("Avg Daily P&L", f"${avg_daily_pnl:,.0f}")
            s3.metric("Win Rate", f"{win_rate:.1f}%")
            s4.metric("Best Day", f"${max_pnl:,.0f}")
            s5.metric("Worst Day", f"${min_pnl:,.0f}")

            # P&L í…Œì´ë¸”
            st.markdown("#### ì¼ë³„ P&L ìƒì„¸")
            st.dataframe(
                daily_pnl[['report_date', 'market_value_usd', 'pnl_usd', 'daily_return', 'cumulative_pnl']].sort_values('report_date', ascending=False).style.format({
                    'report_date': lambda x: x.strftime('%Y-%m-%d'),
                    'market_value_usd': '${:,.0f}',
                    'pnl_usd': '${:,.0f}',
                    'daily_return': '{:.2%}',
                    'cumulative_pnl': '${:,.0f}'
                }),
                use_container_width=True
            )

        with tab_attribution:
            st.markdown("### Contribution ë¶„ì„")

            # ê¸°ê°„ ì„ íƒ
            col_start, col_end = st.columns(2)
            with col_start:
                start_date = st.date_input("ì‹œì‘ì¼", value=min_date.date(), key="attr_start")
            with col_end:
                end_date = st.date_input("ì¢…ë£Œì¼", value=max_date.date(), key="attr_end")

            # ê¸°ê°„ ë‚´ ë°ì´í„°
            df_period = df_underlying[
                (pd.to_datetime(df_underlying['report_date']) >= pd.Timestamp(start_date)) &
                (pd.to_datetime(df_underlying['report_date']) <= pd.Timestamp(end_date))
            ].copy()

            if not df_period.empty:
                # ì¢…ëª©ë³„ Contribution í•©ê³„
                ticker_contrib = df_period.groupby(['ticker', 'name']).agg({
                    'pnl_usd': 'sum',
                    'contribution': 'sum',
                    'market_value_usd': 'last'
                }).reset_index()
                ticker_contrib = ticker_contrib.sort_values('pnl_usd', ascending=False)

                # Contribution ë°” ì°¨íŠ¸ (Top 20)
                top_20_contrib = ticker_contrib.head(20)
                colors = np.where(top_20_contrib['pnl_usd'] >= 0, '#16a34a', '#dc2626')

                fig_contrib = go.Figure(data=go.Bar(
                    x=top_20_contrib['ticker'],
                    y=top_20_contrib['pnl_usd'],
                    text=[f"${v:,.0f}" for v in top_20_contrib['pnl_usd']],
                    textposition='auto',
                    marker_color=colors
                ))
                fig_contrib.update_layout(
                    title="Top 20 Contributors (P&L)",
                    xaxis_title="",
                    yaxis_title="P&L ($)",
                    yaxis_tickformat="$,.0f"
                )
                st.plotly_chart(fig_contrib, use_container_width=True)

                # ì„¹í„°ë³„ Contribution
                if 'sector' in df_period.columns and df_period['sector'].notna().any():
                    sector_contrib = df_period.groupby('sector').agg({
                        'pnl_usd': 'sum',
                        'contribution': 'sum'
                    }).reset_index()
                    sector_contrib = sector_contrib.sort_values('pnl_usd', ascending=False)

                    colors_sector = np.where(sector_contrib['pnl_usd'] >= 0, '#16a34a', '#dc2626')
                    fig_sector_contrib = go.Figure(data=go.Bar(
                        x=sector_contrib['sector'],
                        y=sector_contrib['pnl_usd'],
                        text=[f"${v:,.0f}" for v in sector_contrib['pnl_usd']],
                        textposition='auto',
                        marker_color=colors_sector
                    ))
                    fig_sector_contrib.update_layout(
                        title="Sector Contribution",
                        xaxis_title="",
                        yaxis_title="P&L ($)",
                        yaxis_tickformat="$,.0f"
                    )
                    st.plotly_chart(fig_sector_contrib, use_container_width=True)

                # Contribution í…Œì´ë¸”
                st.markdown("#### ì¢…ëª©ë³„ Contribution ìƒì„¸")
                st.dataframe(
                    ticker_contrib.style.format({
                        'pnl_usd': '${:,.0f}',
                        'contribution': '{:.2f}%',
                        'market_value_usd': '${:,.0f}'
                    }),
                    use_container_width=True
                )
